\begin{thebibliography}{10}

\bibitem{abdul2020cogam}
Ashraf Abdul, Christian von~der Weth, Mohan Kankanhalli, and Brian~Y Lim.
\newblock Cogam: Measuring and moderating cognitive load in machine learning
  model explanations.
\newblock In {\em Proceedings of the 2020 CHI Conference on Human Factors in
  Computing Systems}, pages 1--14, 2020.

\bibitem{aizenberg2020designing}
Evgeni Aizenberg and Jeroen Van Den~Hoven.
\newblock Designing for human rights in ai.
\newblock {\em Big Data \& Society}, 7(2):2053951720949566, 2020.

\bibitem{DBLP:conf/scai/AllahyariL11}
Hiva Allahyari and Niklas Lavesson.
\newblock User-oriented assessment of classification model understandability.
\newblock In Anders Kofod{-}Petersen, Fredrik Heintz, and Helge Langseth,
  editors, {\em Eleventh Scandinavian Conference on Artificial Intelligence,
  {SCAI} 2011, Trondheim, Norway, May 24th - 26th, 2011}, volume 227 of {\em
  Frontiers in Artificial Intelligence and Applications}, pages 11--19. {IOS}
  Press, 2011.

\bibitem{DBLP:journals/corr/abs-2010-14374}
Kasun Amarasinghe, Kit~T. Rodolfa, Hemank Lamba, and Rayid Ghani.
\newblock Explainable machine learning for public policy: Use cases, gaps, and
  research directions.
\newblock {\em CoRR}, abs/2010.14374, 2020.

\bibitem{angwin2016machine}
Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner.
\newblock Machine bias. propublica.
\newblock {\em See https://www. propublica.
  org/article/machine-bias-risk-assessments-in-criminal-sentencing}, 2016.

\bibitem{DBLP:journals/jmlr/AryaBCDHHHLLMMP20}
Vijay Arya, Rachel K.~E. Bellamy, Pin{-}Yu Chen, Amit Dhurandhar, Michael Hind,
  Samuel~C. Hoffman, Stephanie Houde, Q.~Vera Liao, Ronny Luss, Aleksandra
  Mojsilovic, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra, John~T.
  Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush~R.
  Varshney, Dennis Wei, and Yunfeng Zhang.
\newblock {AI} explainability 360: An extensible toolkit for understanding data
  and machine learning models.
\newblock {\em J. Mach. Learn. Res.}, 21:130:1--130:6, 2020.

\bibitem{barocas2020hidden}
Solon Barocas, Andrew~D Selbst, and Manish Raghavan.
\newblock The hidden assumptions behind counterfactual explanations and
  principal reasons.
\newblock In {\em Proceedings of the 2020 Conference on Fairness,
  Accountability, and Transparency}, pages 80--89, 2020.

\bibitem{DBLP:conf/softcomp/BekriKH19}
Nadia~El Bekri, Jasmin Kling, and Marco~F. Huber.
\newblock A study on trust in black box models and post-hoc explanations.
\newblock In Francisco Mart{\'{\i}}nez{-}{\'{A}}lvarez, Alicia~Troncoso Lora,
  Jos{\'{e}} Ant{\'{o}}nio~S{\'{a}}ez Mu{\~{n}}oz, H{\'{e}}ctor Quinti{\'{a}}n,
  and Emilio Corchado, editors, {\em 14th International Conference on Soft
  Computing Models in Industrial and Environmental Applications {(SOCO} 2019) -
  Seville, Spain, May 13-15, 2019, Proceedings}, volume 950 of {\em Advances in
  Intelligent Systems and Computing}, pages 35--46. Springer, 2019.

\bibitem{bell2019proactive}
Andrew Bell, Alexander Rich, Melisande Teng, Tin Ore{\v{s}}kovi{\'c}, Nuno~B
  Bras, L{\'e}nia Mestrinho, Srdan Golubovic, Ivan Pristas, and Leid
  Zejnilovic.
\newblock Proactive advising: a machine learning driven approach to vaccine
  hesitancy.
\newblock In {\em 2019 IEEE International Conference on Healthcare Informatics
  (ICHI)}, pages 1--6. IEEE, 2019.

\bibitem{bhatt2020explainable}
Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan
  Jia, Joydeep Ghosh, Ruchir Puri, José M.~F. Moura, and Peter Eckersley.
\newblock Explainable machine learning in deployment, 2020.

\bibitem{DBLP:conf/fat/BuolamwiniG18}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In Sorelle~A. Friedler and Christo Wilson, editors, {\em Conference
  on Fairness, Accountability and Transparency, {FAT} 2018, 23-24 February
  2018, New York, NY, {USA}}, volume~81 of {\em Proceedings of Machine Learning
  Research}, pages 77--91. {PMLR}, 2018.

\bibitem{caswell2010unemployed}
Dorte Caswell, Greg Marston, and J{\o}rgen~Elm Larsen.
\newblock Unemployed citizen or ‘at risk’client? classification systems and
  employment services in denmark and australia.
\newblock {\em Critical Social Policy}, 30(3):384--404, 2010.

\bibitem{cech2021tackling}
Florian Cech.
\newblock Tackling algorithmic transparency in communal energy accounting
  through participatory design.
\newblock In {\em C\&T'21: Proceedings of the 10th International Conference on
  Communities \& Technologies-Wicked Problems in the Age of Tech}, pages
  258--268, 2021.

\bibitem{DBLP:journals/corr/abs-2004-00668}
Ian Covert, Scott~M. Lundberg, and Su{-}In Lee.
\newblock Dblp:journals/corr/abs-2004-00668 feature contributions through
  additive importance measures.
\newblock {\em CoRR}, abs/2004.00668, 2020.

\bibitem{dai2021fair}
Jessica Dai, Sina Fazelpour, and Zachary Lipton.
\newblock Fair machine learning under partial compliance.
\newblock In {\em Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 55--65, 2021.

\bibitem{datta2016algorithmic}
Anupam Datta, Shayak Sen, and Yair Zick.
\newblock Algorithmic transparency via quantitative input influence: Theory and
  experiments with learning systems.
\newblock In {\em 2016 IEEE symposium on security and privacy (SP)}, pages
  598--617. IEEE, 2016.

\bibitem{de2018predicting}
Inigo~Martinez de~Troya, Ruqian Chen, Laura~O Moraes, Pranjal Bajaj, Jordan
  Kupersmith, Rayid Ghani, Nuno~B Br{\'a}s, and Leid Zejnilovic.
\newblock Predicting, explaining, and understanding risk of long-term
  unemployment.
\newblock In {\em NeurIPS Workshop on AI for Social Good}, 2018.

\bibitem{doshi2017towards}
Finale Doshi-Velez and Been Kim.
\newblock Towards a rigorous science of interpretable machine learning.
\newblock {\em arXiv preprint arXiv:1702.08608}, 2017.

\bibitem{doshi2017accountability}
Finale Doshi-Velez, Mason Kortz, Ryan Budish, Chris Bavitz, Sam Gershman, David
  O'Brien, Kate Scott, Stuart Schieber, James Waldo, David Weinberger, et~al.
\newblock Accountability of ai under the law: The role of explanation.
\newblock {\em arXiv preprint arXiv:1711.01134}, 2017.

\bibitem{edwards2018enslaving}
Lilian Edwards and Michael Veale.
\newblock Enslaving the algorithm: From a “right to an explanation” to a
  “right to better decisions”?
\newblock {\em IEEE Security \& Privacy}, 16(3):46--54, 2018.

\bibitem{eiband2018bringing}
Malin Eiband, Hanna Schneider, Mark Bilandzic, Julian Fazekas-Con, Mareike
  Haug, and Heinrich Hussmann.
\newblock Bringing transparency design into practice.
\newblock In {\em 23rd international conference on intelligent user
  interfaces}, pages 211--223, 2018.

\bibitem{DBLP:journals/internet/GasserA17}
Urs Gasser and Virg{\'{\i}}lio A.~F. Almeida.
\newblock A layered model for {AI} governance.
\newblock {\em {IEEE} Internet Comput.}, 21(6):58--62, 2017.

\bibitem{gill2020policy}
Indermit~S Gill.
\newblock Policy approaches to artificial intelligence based technologies in
  china, european union and the united states.
\newblock 2020.

\bibitem{gillingham2019can}
Philip Gillingham.
\newblock Can predictive algorithms assist decision-making in social work with
  children and families?
\newblock {\em Child abuse review}, 28(2):114--126, 2019.

\bibitem{gunning2019xai}
David Gunning, Mark Stefik, Jaesik Choi, Timothy Miller, Simone Stumpf, and
  Guang-Zhong Yang.
\newblock Xai—explainable artificial intelligence.
\newblock {\em Science Robotics}, 4(37), 2019.

\bibitem{gupta2020participatory}
Abhishek Gupta and Tania De~Gasperis.
\newblock Participatory design to build better contact-and proximity-tracing
  apps.
\newblock {\em arXiv preprint arXiv:2006.00432}, 2020.

\bibitem{hind2019explaining}
Michael Hind.
\newblock Explaining explainable ai.
\newblock {\em XRDS: Crossroads, The ACM Magazine for Students}, 25(3):16--19,
  2019.

\bibitem{DBLP:conf/chi/HohmanHCDD19}
Fred Hohman, Andrew Head, Rich Caruana, Robert DeLine, and Steven~Mark Drucker.
\newblock Gamut: {A} design probe to understand how data scientists understand
  machine learning models.
\newblock In Stephen~A. Brewster, Geraldine Fitzpatrick, Anna~L. Cox, and
  Vassilis Kostakos, editors, {\em Proceedings of the 2019 {CHI} Conference on
  Human Factors in Computing Systems, {CHI} 2019, Glasgow, Scotland, UK, May
  04-09, 2019}, page 579. {ACM}, 2019.

\bibitem{holzinger2020measuring}
Andreas Holzinger, Andr{\'e} Carrington, and Heimo M{\"u}ller.
\newblock Measuring the quality of explanations: the system causability scale
  (scs).
\newblock {\em KI-K{\"u}nstliche Intelligenz}, pages 1--6, 2020.

\bibitem{huysmans2006using}
Johan Huysmans, Bart Baesens, and Jan Vanthienen.
\newblock Using rule extraction to improve the comprehensibility of predictive
  models.
\newblock 2006.

\bibitem{DBLP:journals/corr/abs-2101-09429}
Sheikh~Rabiul Islam, William Eberle, Sheikh~Khaled Ghafoor, and Mohiuddin
  Ahmed.
\newblock Explainable artificial intelligence approaches: {A} survey.
\newblock {\em CoRR}, abs/2101.09429, 2021.

\bibitem{DBLP:journals/corr/abs-1906-11668}
Anna Jobin, Marcello Ienca, and Effy Vayena.
\newblock Artificial intelligence: the global landscape of ethics guidelines.
\newblock {\em CoRR}, abs/1906.11668, 2019.

\bibitem{jung2017simple}
Jongbin Jung, Connor Concannon, Ravi Shroff, Sharad Goel, and Daniel~G
  Goldstein.
\newblock Simple rules for complex decisions.
\newblock {\em arXiv preprint arXiv:1702.04690}, 2017.

\bibitem{DBLP:conf/aies/KrafftYKHB20}
P.~M. Krafft, Meg Young, Michael~A. Katell, Karen Huang, and Ghislain Bugingo.
\newblock Defining {AI} in policy versus practice.
\newblock In Annette~N. Markham, Julia Powles, Toby Walsh, and Anne~L.
  Washington, editors, {\em {AIES} '20: {AAAI/ACM} Conference on AI, Ethics,
  and Society, New York, NY, USA, February 7-8, 2020}, pages 72--78. {ACM},
  2020.

\bibitem{KUZIEMSKI2020101976}
Maciej Kuziemski and Gianluca Misuraca.
\newblock Ai governance in the public sector: Three tales from the frontiers of
  automated decision-making in democratic settings.
\newblock {\em Telecommunications Policy}, 44(6):101976, 2020.
\newblock Artificial intelligence, economy and society.

\bibitem{DBLP:conf/chi/LiaoGM20}
Q.~Vera Liao, Daniel~M. Gruen, and Sarah Miller.
\newblock Questioning the {AI:} informing design practices for explainable {AI}
  user experiences.
\newblock In Regina Bernhaupt, Florian~'Floyd' Mueller, David Verweij, Josh
  Andres, Joanna McGrenere, Andy Cockburn, Ignacio Avellino, Alix Goguey,
  Pernille Bj{\o}n, Shengdong Zhao, Briane~Paul Samson, and Rafal Kocielnik,
  editors, {\em {CHI} '20: {CHI} Conference on Human Factors in Computing
  Systems, Honolulu, HI, USA, April 25-30, 2020}, pages 1--15. {ACM}, 2020.

\bibitem{lipton2018mythos}
Zachary~C Lipton.
\newblock The mythos of model interpretability: In machine learning, the
  concept of interpretability is both important and slippery.
\newblock {\em Queue}, 16(3):31--57, 2018.

\bibitem{loi2021towards}
Michele Loi and Matthias Spielkamp.
\newblock Towards accountability in the use of artificial intelligence for
  public administrations.
\newblock In {\em Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 757--766, 2021.

\bibitem{loxha2014profiling}
Artan Loxha and Matteo Morgandi.
\newblock Profiling the unemployed: a review of oecd experiences and
  implications for emerging economies.
\newblock 2014.

\bibitem{lu2019good}
Joy Lu, Dokyun Lee, Tae~Wan Kim, and David Danks.
\newblock Good explanation for algorithmic transparency.
\newblock {\em Available at SSRN 3503603}, 2019.

\bibitem{DBLP:conf/nips/LundbergL17}
Scott~M. Lundberg and Su{-}In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna~M. Wallach,
  Rob Fergus, S.~V.~N. Vishwanathan, and Roman Garnett, editors, {\em Advances
  in Neural Information Processing Systems 30: Annual Conference on Neural
  Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
  {USA}}, pages 4765--4774, 2017.

\bibitem{malgieri2019automated}
Gianclaudio Malgieri.
\newblock Automated decision-making in the eu member states: The right to
  explanation and other “suitable safeguards” in the national legislations.
\newblock {\em Computer law \& security review}, 35(5):105327, 2019.

\bibitem{DBLP:journals/corr/abs-2012-01805}
Ricards Marcinkevics and Julia~E. Vogt.
\newblock Interpretability and explainability: {A} machine learning zoo
  mini-tour.
\newblock {\em CoRR}, abs/2012.01805, 2020.

\bibitem{matty2013predicting}
Simon Matty.
\newblock {\em Predicting Likelihood of Long-term Unemployment: The Development
  of a UK Jobseekers' Classification Instrument}.
\newblock Corporate Document Services, 2013.

\bibitem{meske}
Christian Meske, Enrico Bunde, Johannes Schneider, and Martin Gersch.
\newblock Explainable artificial intelligence: Objectives, stakeholders and
  future research opportunities.
\newblock {\em Information Systems Management}, 12 2020.

\bibitem{meyers2007street}
Marcia~K Meyers, Susan Vorsanger, B~Guy Peters, and Jon Pierre.
\newblock Street-level bureaucrats and the implementation of public policy.
\newblock {\em The handbook of public administration}, pages 153--163, 2007.

\bibitem{DBLP:journals/corr/Miller17a}
Tim Miller.
\newblock Explanation in artificial intelligence: Insights from the social
  sciences.
\newblock {\em CoRR}, abs/1706.07269, 2017.

\bibitem{molnar2019}
Christoph Molnar.
\newblock {\em Interpretable Machine Learning}.
\newblock 2019.
\newblock \url{https://christophm.github.io/interpretable-ml-book/}.

\bibitem{nichols2013consequences}
Austin Nichols, Josh Mitchell, and Stephan Lindner.
\newblock Consequences of long-term unemployment.
\newblock {\em Washington, DC: The Urban Institute}, 2013.

\bibitem{DBLP:journals/tvcg/PandeyMNSB14}
Anshul~Vikram Pandey, Anjali Manivannan, Oded Nov, Margaret Satterthwaite, and
  Enrico Bertini.
\newblock The persuasive power of data visualization.
\newblock {\em {IEEE} Trans. Vis. Comput. Graph.}, 20(12):2211--2220, 2014.

\bibitem{pandey2015deceptive}
Anshul~Vikram Pandey, Katharina Rall, Margaret~L Satterthwaite, Oded Nov, and
  Enrico Bertini.
\newblock How deceptive are deceptive visualizations? an empirical analysis of
  common distortion techniques.
\newblock In {\em Proceedings of the 33rd annual acm conference on human
  factors in computing systems}, pages 1469--1478, 2015.

\bibitem{10.1145/3306618.3314274}
Jack Parker and David Danks.
\newblock How technological advances can reveal rights.
\newblock In {\em Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
  and Society}, AIES '19, page 201, New York, NY, USA, 2019. Association for
  Computing Machinery.

\bibitem{DBLP:journals/corr/abs-1909-03567}
Andi Peng, Besmira Nushi, Emre Kiciman, Kori Inkpen, Siddharth Suri, and Ece
  Kamar.
\newblock What you see is what you get? the impact of representation criteria
  on human bias in hiring.
\newblock {\em CoRR}, abs/1909.03567, 2019.

\bibitem{preece2018stakeholders}
Alun Preece, Dan Harborne, Dave Braines, Richard Tomsett, and Supriyo
  Chakraborty.
\newblock Stakeholders in explainable ai.
\newblock {\em arXiv preprint arXiv:1810.00184}, 2018.

\bibitem{rakova2020responsible}
Bogdana Rakova, Jingying Yang, Henriette Cramer, and Rumman Chowdhury.
\newblock Where responsible ai meets reality: Practitioner perspectives on
  enablers for shifting organizational practices.
\newblock {\em arXiv preprint arXiv:2006.12358}, 2020.

\bibitem{raso2017displacement}
Jennifer Raso.
\newblock Displacement as regulation: New regulatory technologies and
  front-line decision-making in ontario works.
\newblock {\em Canadian Journal of Law and Society}, 32(1):75--95, 2017.

\bibitem{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock " why should i trust you?" explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144, 2016.

\bibitem{richards2021human}
John~T Richards, David Piorkowski, Michael Hind, Stephanie Houde, Aleksandra
  Mojsilovic, and Kush~R Varshney.
\newblock A human-centered methodology for creating ai factsheets.
\newblock {\em IEEE Data Eng. Bull.}, 44(4):47--58, 2021.

\bibitem{riipinen2011risk}
T~Riipinen.
\newblock Risk profiling of long-term unemployment in finland.
\newblock In {\em Power Point presentation at the European Commission’s
  “PES to PES Dialogue Dissemination Conference,” Brussels, September},
  pages 8--9, 2011.

\bibitem{rodolfa2020machine}
Kit~T. Rodolfa, Hemank Lamba, and Rayid Ghani.
\newblock Machine learning for public policy: Do we need to sacrifice accuracy
  to make models fair?, 2020.

\bibitem{rudin2019stop}
Cynthia Rudin.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock {\em Nature Machine Intelligence}, 1(5):206--215, 2019.

\bibitem{schmidt2020transparency}
Philipp Schmidt, Felix Biessmann, and Timm Teubner.
\newblock Transparency and trust in artificial intelligence systems.
\newblock {\em Journal of Decision Systems}, 29(4):260--278, 2020.

\bibitem{platform2018tackling}
Anette Scoppetta and Arthur Buckenleib.
\newblock Tackling long-term unemployment through risk profiling and outreach.
\newblock 2018.

\bibitem{DBLP:conf/fat/SelbstP18}
Andrew Selbst and Julia Powles.
\newblock "meaningful information" and the right to explanation.
\newblock In Sorelle~A. Friedler and Christo Wilson, editors, {\em Conference
  on Fairness, Accountability and Transparency, {FAT} 2018, 23-24 February
  2018, New York, NY, {USA}}, volume~81 of {\em Proceedings of Machine Learning
  Research}, page~48. {PMLR}, 2018.

\bibitem{DBLP:conf/aies/SlackHJSL20}
Dylan Slack, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju.
\newblock Fooling {LIME} and {SHAP:} adversarial attacks on post hoc
  explanation methods.
\newblock In Annette~N. Markham, Julia Powles, Toby Walsh, and Anne~L.
  Washington, editors, {\em {AIES} '20: {AAAI/ACM} Conference on AI, Ethics,
  and Society, New York, NY, USA, February 7-8, 2020}, pages 180--186. {ACM},
  2020.

\bibitem{DBLP:journals/corr/abs-2001-09734}
Kacper Sokol and Peter~A. Flach.
\newblock One explanation does not fit all: The promise of interactive
  explanations for machine learning transparency.
\newblock {\em CoRR}, abs/2001.09734, 2020.

\bibitem{stiglic2015comprehensible}
Gregor Stiglic, Petra Povalej~Brzan, Nino Fijacko, Fei Wang, Boris Delibasic,
  Alexandros Kalousis, and Zoran Obradovic.
\newblock Comprehensible predictive modeling using regularized logistic
  regression and comorbidity based features.
\newblock {\em PloS one}, 10(12):e0144439, 2015.

\bibitem{stoyanovich2016revealing}
Julia Stoyanovich and Ellen~P Goodman.
\newblock Revealing algorithmic rankers.
\newblock {\em Freedom to Tinker (August 5 2016)}, 2016.

\bibitem{DBLP:journals/pvldb/StoyanovichHJ20}
Julia Stoyanovich, Bill Howe, and H.V. Jagadish.
\newblock Responsible data management.
\newblock {\em PVLDB}, 13(12):3474--3489, 2020.

\bibitem{sztandar2018changing}
Karolina Sztandar-Sztanderska and Marianna Zielenska.
\newblock Changing social citizenship through information technology.
\newblock {\em Social Work \& Society}, 16(2), 2018.

\bibitem{tal2016blinded}
Aner Tal and Brian Wansink.
\newblock Blinded with science: Trivial graphs and formulas increase ad
  persuasiveness and belief in product efficacy.
\newblock {\em Public Understanding of Science}, 25(1):117--125, 2016.

\bibitem{unicri}
UNICRI.
\newblock Towards responsible artificial intelligence innovation.
\newblock 2020.

\bibitem{ustun2019actionable}
Berk Ustun, Alexander Spangher, and Yang Liu.
\newblock Actionable recourse in linear classification.
\newblock In {\em Proceedings of the conference on fairness, accountability,
  and transparency}, pages 10--19, 2019.

\bibitem{ventocilla2018towards}
Elio Ventocilla, Tove Helldin, Maria Riveiro, Juhee Bae, Veselka Boeva,
  G{\"o}ran Falkman, and Niklas Lavesson.
\newblock Towards a taxonomy for interpretable and interactive machine
  learning.
\newblock In {\em XAI Workshop on Explainable Artificial Intelligence}, pages
  151--157, 2018.

\bibitem{wachter2017transparent}
Sandra Wachter, Brent Mittelstadt, and Luciano Floridi.
\newblock Transparent, explainable, and accountable ai for robotics.
\newblock 2017.

\bibitem{wachter2017counterfactual}
Sandra Wachter, Brent Mittelstadt, and Chris Russell.
\newblock Counterfactual explanations without opening the black box: Automated
  decisions and the gdpr.
\newblock {\em Harv. JL \& Tech.}, 31:841, 2017.

\bibitem{wagner2019liable}
Ben Wagner.
\newblock Liable, but not in control? ensuring meaningful human agency in
  automated decision-making systems.
\newblock {\em Policy \& Internet}, 11(1):104--122, 2019.

\bibitem{yang2020fairness}
Ke~Yang, Biao Huang, Julia Stoyanovich, and Sebastian Schelter.
\newblock Fairness-aware instrumentation of preprocessing pipelines for machine
  learning.
\newblock In {\em HILDA workshop at SIGMOD}, 2020.

\bibitem{yang2019study}
Yiwei Yang, Eser Kandogan, Yunyao Li, Prithviraj Sen, and Walter~S Lasecki.
\newblock A study on interaction in human-in-the-loop machine learning for text
  analytics.
\newblock In {\em IUI Workshops}, 2019.

\bibitem{zejnilovic2020algorithmic}
Leid Zejnilovi{\'c}, Susana Lavado, {\'I}{\~n}igo Mart{\'\i}nez de Rituerto~de
  Troya, Samantha Sim, and Andrew Bell.
\newblock Algorithmic long-term unemployment risk assessment in use:
  Counselors’ perceptions and use practices.
\newblock {\em Global Perspectives}, 1(1), 2020.

\bibitem{zhang2019should}
Yujia Zhang, Kuangyan Song, Yiming Sun, Sarah Tan, and Madeleine Udell.
\newblock " why should you trust my explanation?" understanding uncertainty in
  lime explanations.
\newblock {\em arXiv preprint arXiv:1904.12991}, 2019.

\end{thebibliography}
