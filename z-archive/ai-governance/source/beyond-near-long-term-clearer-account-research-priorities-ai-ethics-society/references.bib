@article{newellmarabelli2015,
  title={Strategic opportunities (and challenges) of algorithmic decision-making: A call for action on the long-term societal effects of `datification'},
  author={Newell, Sue and Marabelli, Marco},
  journal={The Journal of Strategic Information Systems},
  volume={24},
  number={1},
  pages={3--14},
  year={2015},
  publisher={Elsevier}
}

@book{brockman2019,
    title={{Possible} {Minds}: {Twenty}-{Five} {Ways} of {Looking} at {AI}},
    author={Brockman, John},
    year={2019},
    publisher={Penguin Press}
}

@article{tucker2018privacy,
  title={Privacy, algorithms, and artificial intelligence},
  author={Tucker, Catherine},
  journal={The Economics of Artificial Intelligence: An Agenda},
  year={2018},
  publisher={University of Chicago Press}
}

@book{zuboff2019age,
  title={The age of surveillance capitalism: The fight for a human future at the new frontier of power},
  author={Zuboff, Shoshana},
  year={2019},
  publisher={Profile Books}
}

@inproceedings{hajian2016algorithmic,
  title={Algorithmic bias: From discrimination discovery to fairness-aware data mining},
  author={Hajian, Sara and Bonchi, Francesco and Castillo, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={2125--2126},
  year={2016},
  organization={ACM}
}

@article{goodall2016can,
  title={Can you program ethics into a self-driving car?},
  author={Goodall, Noah J},
  journal={IEEE Spectrum},
  volume={53},
  number={6},
  pages={28--58},
  year={2016},
  publisher={IEEE}
}

@article{koene2017algorithmic,
  title={Algorithmic Bias: Addressing Growing Concerns [Leading Edge]},
  author={Koene, Ansgar},
  journal={IEEE Technology and Society Magazine},
  volume={36},
  number={2},
  pages={31--32},
  year={2017},
  publisher={IEEE}
}

@article{bonnefon2016social,
  title={The social dilemma of autonomous vehicles},
  author={Bonnefon, Jean-Fran{\c{c}}ois and Shariff, Azim and Rahwan, Iyad},
  journal={Science},
  volume={352},
  number={6293},
  pages={1573--1576},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{asaro2012banning,
  title={On banning autonomous weapon systems: human rights, automation, and the dehumanization of lethal decision-making},
  author={Asaro, Peter},
  journal={International Review of the Red Cross},
  volume={94},
  number={886},
  pages={687--709},
  year={2012},
  publisher={Cambridge University Press}
}

@article{anderson2013law,
  title={Law and ethics for autonomous weapon systems: Why a ban won't work and how the laws of war can},
  author={Anderson, Kenneth and Waxman, Matthew C},
  year={2013},
  publisher={Stanford University, The Hoover Institution}
}

@book{ford2019,
    title={{Architects} of {Intelligence}: {The} truth abut {AI} from the people building it},
    author={Martin Ford},
    year={2019},
    publisher={Packt Publishing}
}

@misc{sittler2019,
    title={A shift in arguments for {AI} risk},
    author={Sittler, Tom},
    year={2019},
    howpublished={https://fragile-credences.github.io/prioritising-ai/}
}

@misc{ngo2019,
    title={Disentangling arguments for the importance of {AI} safety},
    author={Ngo, Richard},
    year={2019},
    howpublished={https://thinkingcomplete.blogspot.com/2019/01/disentangling-arguments-for-importance.html}
}

@book{tegmark2017,
  title={Life 3.0: Being human in the age of artificial intelligence},
  author={Tegmark, Max},
  year={2017},
  publisher={Knopf}
}

@article{crawfordcalo2016,
  title={There is a blind spot in {AI} research},
  author={Crawford, Kate and Calo, Ryan},
  journal={Nature News},
  volume={538},
  number={7625},
  pages={311},
  year={2016}
}

@article{gruetzemacher_2019,
    title={{Defining} and {Unpacking} {Transformative} {AI}},
    author={Gruetzemacher, Ross and Whittlestone, Jess},
    journal={Effective Altruism Global, London 2019},
    year={2019}
}

@misc{whitehouse_2016,
    title = {{Preparing} {For} {The} {Future} {Of} {Artificial} {Intelligence}},
    year={2016},
    author= {National Science and Technology Council (Obama White House)}
}

@article{dafoe_ai_2018,
	title = {{AI} {Governance}: {A} {Research} {Agenda}},
	journal = {Center for the Governance of AI, Future of Humanity Institute, University of Oxford},
	author = {Dafoe, Allan},
	year = {2018}
}

@article{garling_why_2015,
    title = {{Andrew} {Ng}: {Why} `{Deep} {Learning}' is a mandate for humans, not just machines.},
    journal = {Wired},
    author = {Garling, Caleb},
    year = {2015}
    }
    
@book{parfit_equality_1991,
  title={Equality or priority},
  author={Parfit, Derek},
  year={1991},
  publisher={University of Kansas, Department of Philosophy}
}

@article{parfit_future_2017,
  title={Future people, the non-identity problem, and person-affecting principles},
  author={Parfit, Derek},
  journal={Philosophy \& Public Affairs},
  volume={45},
  number={2},
  pages={118--157},
  year={2017},
  publisher={Wiley Online Library}
}

@article{crawford_artificial_2016,
    title = {Artifical {I}ntelligence's {W}hite {G}uy {P}roblem.},
    journal = {The {New} {York} {Times}},
    author = {Crawford, Kate},
    year = {2016}
    }

@article{etzioni_no_2016,
    title = {No, the {Experts} {Don't} {Think} {Superintelligent} {AI} is a {Threat} to {Humanity}},
    journal = {{MIT} {T}echnology {R}eview},
    author = {Etzioni, Oren},
    month = sep,
    year = {2016},
    }
    
@article{dafoe_yes_2016,
    title = {Yes, {We} {Are} {Worried} {About} the {Existential} {Risk} of {Artificial} {Intelligence}},
    journal = {{MIT} {T}echnology {R}eview},
    author = {Dafoe, Allan and Russel, Stuart},
    month = nov,
    year = {2016},
    }
    
    @book{whittaker_ai_2018,
  title={AI now report 2018},
  author={Whittaker, Meredith and Crawford, Kate and Dobbe, Roel and Fried, Genevieve and Kaziunas, Elizabeth and Mathur, Varoon and West, Sarah Mysers and Richardson, Rashida and Schultz, Jason and Schwartz, Oscar},
  year={2018},
  publisher={AI Now Institute at New York University}
}

@book{bostrom_superintelligence_2014,
	address = {Oxford},
	title = {Superintelligence: {Paths}, {Dangers}, {Strategies}},
	language = {English},
	publisher = {OUP Oxford},
	author = {Bostrom, Nick},
	year = {2014}
}

@misc{karnofsky_potential_2016,
	title = {Potential {Risks} from {Advanced} {Artificial} {Intelligence}: {The} {Philanthropic} {Opportunity}},
	howpublished = {https://www.openphilanthropy.org/blog/potential-risks-advanced-artificial-intelligence-philanthropic-opportunity},
	journal = {Open Philanthropy Project},
	author = {Karnofsky, Holden},
	month = may,
	year = {2016}
}

@article{buch_artificial_2018,
	title = {Artificial intelligence in medicine: current trends and future possibilities},
	volume = {68},
	copyright = {© British Journal of General Practice 2018},
	issn = {0960-1643, 1478-5242},
	shorttitle = {Artificial intelligence in medicine},
	url = {https://bjgp.org/content/68/668/143},
	doi = {10.3399/bjgp18X695213},
	language = {en},
	number = {668},
	urldate = {2019-10-31},
	journal = {British Journal of General Practice},
	author = {Buch, Varun H. and Ahmed, Irfan and Maruthappu, Mahiben},
	month = mar,
	year = {2018},
	pmid = {29472224},
	pages = {143--144}
}

@techreport{richardson_dirty_2019,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Dirty {Data}, {Bad} {Predictions}: {How} {Civil} {Rights} {Violations} {Impact} {Police} {Data}, {Predictive} {Policing} {Systems}, and {Justice}},
	shorttitle = {Dirty {Data}, {Bad} {Predictions}},
	url = {https://papers.ssrn.com/abstract=3333423},
	abstract = {Law enforcement agencies are increasingly using predictive policing systems to forecast criminal activity and allocate police resources. Yet in numerous jurisdictions, these systems are built on data produced during documented periods of flawed, racially biased, and sometimes unlawful practices and policies (“dirty policing”). These policing practices and policies shape the environment and the methodology by which data is created, which raises the risk of creating inaccurate, skewed, or systemically biased data (“dirty data”). If predictive policing systems are informed by such data, they cannot escape the legacies of the unlawful or biased policing practices that they are built on. Nor do current claims by predictive policing vendors provide sufficient assurances that their systems adequately mitigate or segregate this data.In our research, we analyze thirteen jurisdictions that have used or developed predictive policing tools while under government commission investigations or federal court monitored settlements, consent decrees, or memoranda of agreement stemming from corrupt, racially biased, or otherwise illegal policing practices. In particular, we examine the link between unlawful and biased police practices and the data available to train or implement these systems. We highlight three case studies: (1) Chicago, an example of where dirty data was ingested directly into the city’s predictive system; (2) New Orleans, an example where the extensive evidence of dirty policing practices and recent litigation suggests an extremely high risk that dirty data was or could be used in predictive policing; and (3) Maricopa County, where despite extensive evidence of dirty policing practices, a lack of public transparency about the details of various predictive policing systems restricts a proper assessment of the risks. The implications of these findings have widespread ramifications for predictive policing writ large. Deploying predictive policing systems in jurisdictions with extensive histories of unlawful police practices presents elevated risks that dirty data will lead to flawed or unlawful predictions, which in turn risk perpetuating additional harm via feedback loops throughout the criminal justice system. The use of predictive policing must be treated with high levels of caution and mechanisms for the public to know, assess, and reject such systems are imperative.},
	language = {en},
	number = {ID 3333423},
	urldate = {2019-10-31},
	institution = {Social Science Research Network},
	author = {Richardson, Rashida and Schultz, Jason and Crawford, Kate},
	month = feb,
	year = {2019},
	keywords = {AI, Bias, Civil Rights, Data, Justice, Machine Learning, Policing, Predictive Policing}
}

@article{baum2018,
  title={Reconciliation between factions focused on near-term and long-term artificial intelligence},
  author={Baum, Seth D},
  journal={AI \& SOCIETY},
  volume={33},
  number={4},
  pages={565--572},
  year={2018},
  publisher={Springer}
}

@article{krakovna_is_2018,
	title = {Is {There} a {Trade}-{Off} {Between} {Immediate} and {Longer}-term {AI} {Safety} {Efforts}?},
	url = {https://futureoflife.org/2018/01/29/trade-off-immediate-longer-term-ai-safety-efforts/},
	journal = {Future of Life Institute News},
	author = {Krakovna, Viktoriya},
	year = {2018}
}

@article{parson_artificial_2019,
	title = {Artificial {Intelligence} in {Strategic} {Context}: {An} {Introduction}},
	author = {Parson, Edward and Re, Richard and Solow-Niederman, Alicia and Zeide, Elana},
	howpublished={aipulse.org/artificial-intelligence-in-strategic-context-an-introduction/},
	year = {2019}
}

@techreport{brundage_guide_2017,
	title = {Guide to working in {AI} policy and strategy},
	url = {https://80000hours.org/articles/ai-policy-guide/},
	author = {Brundage, Miles},
	year = {2017}
}

@article{cave_bridging_2019,
	title = {Bridging near- and long-term concerns about {AI}},
	volume = {1},
	copyright = {2019 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-018-0003-2},
	doi = {10.1038/s42256-018-0003-2},
	abstract = {Debate about the impacts of AI is often split into two camps, one associated with the near term and the other with the long term. This divide is a mistake — the connections between the two perspectives deserve more attention, say Stephen Cave and Seán S. ÓhÉigeartaigh.},
	language = {en},
	number = {1},
	urldate = {2019-10-30},
	journal = {Nature Machine Intelligence},
	author = {Cave, Stephen and ÓhÉigeartaigh, Seán S.},
	month = jan,
	year = {2019},
	pages = {5--6}
}