@article{gibson2019efficiency,
  title={How efficiency shapes human language},
  author={Gibson, Edward and Futrell, Richard and Piantadosi, Steven P and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
  journal={Trends in cognitive sciences},
  volume={23},
  number={5},
  pages={389--407},
  year={2019},
  publisher={Elsevier}
}

@online{mum,
  title = {MUM: A new AI milestone for understanding information},
  year = 2021,
  url = {https://blog.google/products/search/introducing-mum/}
}

@online{meb,
  title = {Make Every feature Binary: A 135B parameter sparse neural network for massively improved search relevance
},
  year = 2021
}

@article{team2022NoLL,
  title={No Language Left Behind: Scaling Human-Centered Machine Translation},
  author={Nllb team and Marta Ruiz Costa-juss{\`a} and James Cross and Onur cCelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Alison Youngblood and Bapi Akula and Lo{\"i}c Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon L. Spruit and C. Tran and Pierre Yves Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzm'an and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.04672}
}

@misc{palm,
  doi = {10.48550/ARXIV.2204.02311},
  
  url = {https://arxiv.org/abs/2204.02311},
  
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {PaLM: Scaling Language Modeling with Pathways},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{lee2022coauthor,
  title={Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities},
  author={Lee, Mina and Liang, Percy and Yang, Qian},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2022}
}

@article{liptak2017amazon,
  title={Amazon’s Alexa started ordering people dollhouses after hearing its name on TV},
  author={Liptak, Andrew},
  journal={The Verge},
  volume={7},
  year={2017}
}
@online{GoogleHome,
title = {Google Home},
url = {https://home.google.com/}
}

@article{wolf2017we,
  title={Why we should have seen that coming: comments on Microsoft's tay" experiment," and wider implications},
  author={Wolf, Marty J and Miller, K and Grodzinsky, Frances S},
  journal={Acm Sigcas Computers and Society},
  volume={47},
  number={3},
  pages={54--64},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{abdi2019more,
  title={More than Smart Speakers: Security and Privacy Perceptions of Smart Home Personal Assistants.},
  author={Abdi, Noura and Ramokapane, Kopo M and Such, Jose M},
  booktitle={SOUPS@ USENIX Security Symposium},
  year={2019}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@inproceedings{jin2021good,
  title={How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact},
  author={Jin, Zhijing and Chauhan, Geeticka and Tse, Brian and Sachan, Mrinmaya and Mihalcea, Rada},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={3099--3113},
  year={2021}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@inproceedings{liang2021towards,
  title={Towards understanding and mitigating social biases in language models},
  author={Liang, Paul Pu and Wu, Chiyu and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={International Conference on Machine Learning},
  pages={6565--6576},
  year={2021},
  organization={PMLR}
}

@article{schuster2020limitations,
  title={The limitations of stylometry for detecting machine-generated fake news},
  author={Schuster, Tal and Schuster, Roei and Shah, Darsh J and Barzilay, Regina},
  journal={Computational Linguistics},
  volume={46},
  number={2},
  pages={499--510},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{lucy2021gender,
  title={Gender and representation bias in GPT-3 generated stories},
  author={Lucy, Li and Bamman, David},
  booktitle={Proceedings of the Third Workshop on Narrative Understanding},
  pages={48--55},
  year={2021}
}

@inproceedings{abid2021persistent,
  title={Persistent anti-muslim bias in large language models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={298--306},
  year={2021}
}

@inproceedings{henderson2018ethical,
  title={Ethical challenges in data-driven dialogue systems},
  author={Henderson, Peter and Sinha, Koustuv and Angelard-Gontier, Nicolas and Ke, Nan Rosemary and Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
  booktitle={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={123--129},
  year={2018}
}

@inproceedings{si2022so,
  title={Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots},
  author={Si, Wai Man and Backes, Michael and Blackburn, Jeremy and De Cristofaro, Emiliano and Stringhini, Gianluca and Zannettou, Savvas and Zhang, Yang},
  booktitle={Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2659--2673},
  year={2022}
}

@article{roller2020recipes,
  title={Recipes for building an open-domain chatbot},
  author={Roller, Stephen and Dinan, Emily and Goyal, Naman and Ju, Da and Williamson, Mary and Liu, Yinhan and Xu, Jing and Ott, Myle and Shuster, Kurt and Smith, Eric M and others},
  journal={arXiv preprint arXiv:2004.13637},
  year={2020}
}

@article{miller2017parlai,
  title={ParlAI: A Dialog Research Software Platform},
  author={Miller, Alexander H and Feng, Will and Fisch, Adam and Lu, Jiasen and Batra, Dhruv and Bordes, Antoine and Parikh, Devi and Weston, Jason},
  journal={EMNLP 2017},
  pages={79},
  year={2017}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{khurana2022natural,
  title={Natural language processing: State of the art, current trends and challenges},
  author={Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
  journal={Multimedia tools and applications},
  pages={1--32},
  year={2022},
  publisher={Springer}
}

@article{goldstein2023generative,
  title={Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations},
  author={Goldstein, Josh A and Sastry, Girish and Musser, Micah and DiResta, Renee and Gentzel, Matthew and Sedova, Katerina},
  journal={arXiv preprint arXiv:2301.04246},
  year={2023}
}

@article{jobin2019global,
  title={The global landscape of AI ethics guidelines},
  author={Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  journal={Nature Machine Intelligence},
  volume={1},
  number={9},
  pages={389--399},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{taddeo2018ai,
  title={How AI can be a force for good},
  author={Taddeo, Mariarosaria and Floridi, Luciano},
  journal={Science},
  volume={361},
  number={6404},
  pages={751--752},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{higashinaka2018role,
  title={Role play-based question-answering by real users for building chatbots with consistent personalities},
  author={Higashinaka, Ryuichiro and Mizukami, Masahiro and Kawabata, Hidetoshi and Yamaguchi, Emi and Adachi, Noritake and Tomita, Junji},
  booktitle={Proceedings of the 19th annual sigdial meeting on discourse and dialogue},
  pages={264--272},
  year={2018}
}
@article{reisenbichler2022frontiers,
  title={Frontiers: Supporting Content Marketing with Natural Language Generation},
  author={Reisenbichler, Martin and Reutterer, Thomas and Schweidel, David A and Dan, Daniel},
  journal={Marketing Science},
  volume={41},
  number={3},
  pages={441--452},
  year={2022},
  publisher={INFORMS}
}
@inproceedings{bartz2008natural,
  title={Natural language generation for sponsored-search advertisements},
  author={Bartz, Kevin and Barr, Cory and Aijaz, Adil},
  booktitle={Proceedings of the 9th ACM Conference on Electronic Commerce},
  pages={1--9},
  year={2008}
}

@inproceedings{nadeem2021stereoset,
  title={StereoSet: Measuring stereotypical bias in pretrained language models},
  author={Nadeem, Moin and Bethke, Anna and Reddy, Siva},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={5356--5371},
  year={2021}
}

@article{kirk2021bias,
  title={Bias out-of-the-box: An empirical analysis of intersectional occupational biases in popular generative language models},
  author={Kirk, Hannah Rose and Jun, Yennie and Volpin, Filippo and Iqbal, Haider and Benussi, Elias and Dreyer, Frederic and Shtedritski, Aleksandar and Asano, Yuki},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={2611--2624},
  year={2021}
}

@inproceedings{carlini2021extracting,
  title={Extracting Training Data from Large Language Models.},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom B and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={USENIX Security Symposium},
  volume={6},
  year={2021}
}

@article{wei2022ai,
  title={Ai ethics issues in real world: Evidence from ai incident database},
  author={Wei, Mengyi and Zhou, Zhixuan},
  journal={arXiv preprint arXiv:2206.07635},
  year={2022}
}

@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}
@article{zhang2018deep,
  title={Deep learning for sentiment analysis: A survey},
  author={Zhang, Lei and Wang, Shuai and Liu, Bing},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={8},
  number={4},
  pages={e1253},
  year={2018},
  publisher={Wiley Online Library}
}

@article{minaee2021deep,
  title={Deep learning--based text classification: a comprehensive review},
  author={Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={3},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{abbasiantaeb2021text,
  title={Text-based question answering from information retrieval and deep neural network perspectives: A survey},
  author={Abbasiantaeb, Zahra and Momtazi, Saeedeh},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={11},
  number={6},
  pages={e1412},
  year={2021},
  publisher={Wiley Online Library}
}
@article{mcguffie2020radicalization,
  title={The radicalization risks of GPT-3 and advanced neural language models},
  author={McGuffie, Kris and Newhouse, Alex},
  journal={arXiv preprint arXiv:2009.06807},
  year={2020}
}

@article{jang2021towards,
  title={Towards continual knowledge learning of language models},
  author={Jang, Joel and Ye, Seonghyeon and Yang, Sohee and Shin, Joongbo and Han, Janghoon and Kim, Gyeonghun and Choi, Stanley Jungkyu and Seo, Minjoon},
  journal={arXiv preprint arXiv:2110.03215},
  year={2021}
}

@inproceedings{gehman2020realtoxicityprompts,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={3356--3369},
  year={2020}
}

@article{solaiman2021process,
  title={Process for adapting language models to society (palms) with values-targeted datasets},
  author={Solaiman, Irene and Dennison, Christy},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5861--5873},
  year={2021}
}

@inproceedings{parrish2022bbq,
  title={BBQ: A hand-built bias benchmark for question answering},
  author={Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={2086--2105},
  year={2022}
}

@inproceedings{dhamala2021bold,
  title={Bold: Dataset and metrics for measuring biases in open-ended language generation},
  author={Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={862--872},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{post-2018-call,
  title = "A Call for Clarity in Reporting {BLEU} Scores",
  author = "Post, Matt",
  booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
  month = oct,
  year = "2018",
  address = "Belgium, Brussels",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/W18-6319",
  pages = "186--191",
}

@article{goyal2022flores,
  title={The flores-101 evaluation benchmark for low-resource and multilingual machine translation},
  author={Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and Ju, Da and Krishnan, Sanjana and Ranzato, Marc’Aurelio and Guzm{\'a}n, Francisco and Fan, Angela},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={522--538},
  year={2022},
  publisher={MIT Press}
}

@inproceedings{popovic2015chrf,
  title={chrF: character n-gram F-score for automatic MT evaluation},
  author={Popovi{\'c}, Maja},
  booktitle={Proceedings of the tenth workshop on statistical machine translation},
  pages={392--395},
  year={2015}
}

@article{kim2022prosocialdialog,
  title={Prosocialdialog: A prosocial backbone for conversational agents},
  author={Kim, Hyunwoo and Yu, Youngjae and Jiang, Liwei and Lu, Ximing and Khashabi, Daniel and Kim, Gunhee and Choi, Yejin and Sap, Maarten},
  journal={arXiv preprint arXiv:2205.12688},
  year={2022}
}
@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@inproceedings{clark2019boolq,
  title={BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={2924--2936},
  year={2019}
}

@article{dhole2021nl,
  title={Nl-augmenter: A framework for task-sensitive natural language augmentation},
  author={Dhole, Kaustubh D and Gangal, Varun and Gehrmann, Sebastian and Gupta, Aadesh and Li, Zhenhao and Mahamood, Saad and Mahendiran, Abinaya and Mille, Simon and Srivastava, Ashish and Tan, Samson and others},
  journal={arXiv preprint arXiv:2112.02721},
  year={2021}
}

@inproceedings{gardner2020evaluating,
  title={Evaluating Models’ Local Decision Boundaries via Contrast Sets},
  author={Gardner, Matt and Artzi, Yoav and Basmov, Victoria and Berant, Jonathan and Bogin, Ben and Chen, Sihao and Dasigi, Pradeep and Dua, Dheeru and Elazar, Yanai and Gottumukkala, Ananth and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={1307--1323},
  year={2020}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}



@online{ethical-constraint,
  title = {ChatGPT has a handful of ethical constraints that are currently being tested
},
  year = 2022,
  url = {https://ordinary-times.com/2022/12/02/chatgpt-has-a-handful-of-ethical-constraints-that-are-currently-being-tested/}
}

@inproceedings{mihaylov2018can,
  title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering},
  author={Mihaylov, Todor and Clark, Peter and Khot, Tushar and Sabharwal, Ashish},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2381--2391},
  year={2018}
}

@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@online{openai-chatgpt,
  title = {ChatGPT: Optimizing
Language Models
for DialogueChatGPT: Optimizing
Language Models
for Dialogue
},
  year = 2022,
  url = {https://openai.com/blog/chatgpt/}
}



@article{ji2022survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  publisher={ACM New York, NY}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{alzantot2018generating,
  title={Generating Natural Language Adversarial Examples},
  author={Alzantot, Moustafa and Sharma, Yash Sharma and Elgohary, Ahmed and Ho, Bo-Jhang and Srivastava, Mani and Chang, Kai-Wei},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  year={2018}
}

@inproceedings{li2020bert,
  title={BERT-ATTACK: Adversarial Attack Against BERT Using BERT},
  author={Li, Linyang and Ma, Ruotian and Guo, Qipeng and Xue, Xiangyang and Qiu, Xipeng},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={6193--6202},
  year={2020}
}

@inproceedings{talat2022you,
  title={You reap what you sow: On the challenges of bias evaluation under multilingual settings},
  author={Talat, Zeerak and N{\'e}v{\'e}ol, Aur{\'e}lie and Biderman, Stella and Clinciu, Miruna and Dey, Manan and Longpre, Shayne and Luccioni, Sasha and Masoud, Maraim and Mitchell, Margaret and Radev, Dragomir and others},
  booktitle={Proceedings of BigScience Episode\# 5--Workshop on Challenges \& Perspectives in Creating Large Language Models},
  pages={26--41},
  year={2022}
}

@misc{Gokaslan2019OpenWeb,  
	title={OpenWebText Corpus},
	author={Aaron Gokaslan and Vanya Cohen},
	url={http://Skylion007.github.io/OpenWebTextCorpus}, 
	year={2019}
}

@article{armengol2021multilingual,
  title={On the Multilingual Capabilities of Very Large-Scale English Language Models},
  author={Armengol-Estap{\'e}, Jordi and Bonet, Ona de Gibert and Melero, Maite},
  journal={arXiv preprint arXiv:2108.13349},
  year={2021}
}



@online{chatgpt-multilingual,
  title = {ChatGPT is multilingual but monocultural, and it’s learning your values
},
  year = 2022,
  url = {https://jilltxt.net/right-now-chatgpt-is-multilingual-but-monocultural-but-its-learning-your-values/}
}

@inproceedings{sawhney2021empirical,
  title={An empirical investigation of bias in the multimodal analysis of financial earnings calls},
  author={Sawhney, Ramit and Aggarwal, Arshiya and Shah, Rajiv},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={3751--3757},
  year={2021}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{weiemergent,
  title={Emergent Abilities of Large Language Models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={Transactions on Machine Learning Research}
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{villalobos2022will,
  title={Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning},
  author={Villalobos, Pablo and Sevilla, Jaime and Heim, Lennart and Besiroglu, Tamay and Hobbhahn, Marius and Ho, Anson},
  journal={arXiv preprint arXiv:2211.04325},
  year={2022}
}
@article{northcutt2021confident,
  title={Confident learning: Estimating uncertainty in dataset labels},
  author={Northcutt, Curtis and Jiang, Lu and Chuang, Isaac},
  journal={Journal of Artificial Intelligence Research},
  volume={70},
  pages={1373--1411},
  year={2021}
}
@article{treviso2022efficient,
  title={Efficient methods for natural language processing: a survey},
  author={Treviso, Marcos and Ji, Tianchu and Lee, Ji-Ung and van Aken, Betty and Cao, Qingqing and Ciosici, Manuel R and Hassid, Michael and Heafield, Kenneth and Hooker, Sara and Martins, Pedro H and others},
  journal={arXiv preprint arXiv:2209.00099},
  year={2022}
}

@inproceedings{lee2022deduplicating,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8424--8445},
  year={2022}
}

@inproceedings{mishra2020we,
  title={Do we need to create big datasets to learn a task?},
  author={Mishra, Swaroop and Sachdeva, Bhavdeep Singh},
  booktitle={Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing},
  pages={169--173},
  year={2020}
}

@inproceedings{Bengio2009CurriculumL,
  title={Curriculum learning},
  author={Yoshua Bengio and J{\'e}r{\^o}me Louradour and Ronan Collobert and Jason Weston},
  booktitle={International Conference on Machine Learning},
  year={2009}
}

@article{Ren2020ASO,
  title={A Survey of Deep Active Learning},
  author={Pengzhen Ren and Yun Xiao and Xiaojun Chang and Po-Yao Huang and Zhihui Li and Xiaojiang Chen and Xin Wang},
  journal={ACM Computing Surveys (CSUR)},
  year={2020},
  volume={54},
  pages={1 - 40}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}

@article{thompson2020computational,
  title={The computational limits of deep learning},
  author={Thompson, Neil C and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F},
  journal={arXiv preprint arXiv:2007.05558},
  year={2020}
}

@article{wu2022sustainable,
  title={Sustainable ai: Environmental implications, challenges and opportunities},
  author={Wu, Carole-Jean and Raghavendra, Ramya and Gupta, Udit and Acun, Bilge and Ardalani, Newsha and Maeng, Kiwan and Chang, Gloria and Aga, Fiona and Huang, Jinshi and Bai, Charles and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={4},
  pages={795--813},
  year={2022}
}

@online{llm-remarks,
  title = {Some remarks on Large Language Model
},
  year = 2023,
  author={Goldberg, Yoav},
  url = {https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9}
}

@inproceedings{DeCao2021EditingFK,
  title={Editing Factual Knowledge in Language Models},
  author={Nicola De Cao and Wilker Aziz and Ivan Titov},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}

@article{Zhu2020ModifyingMI,
  title={Modifying Memories in Transformer Models},
  author={Chen Zhu and Ankit Singh Rawat and Manzil Zaheer and Srinadh Bhojanapalli and Daliang Li and Felix X. Yu and Sanjiv Kumar},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.00363}
}

@inproceedings{mitchellfast,
  title={Fast Model Editing at Scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D},
  booktitle={International Conference on Learning Representations}
}

@article{yang2022diffsound,
  title={Diffsound: Discrete diffusion model for text-to-sound generation},
  author={Yang, Dongchao and Yu, Jianwei and Wang, Helin and Wang, Wen and Weng, Chao and Zou, Yuexian and Yu, Dong},
  journal={arXiv preprint arXiv:2207.09983},
  year={2022}
}

@article{kreuk2022audiogen,
  title={Audiogen: Textually guided audio generation},
  author={Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and D{\'e}fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
  journal={arXiv preprint arXiv:2209.15352},
  year={2022}
}

@article{borsos2022audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2209.03143},
  year={2022}
}

@misc{musiclm,
  doi = {10.48550/ARXIV.2301.11325},
  
  url = {https://arxiv.org/abs/2301.11325},
  
  author = {Agostinelli, Andrea and Denk, Timo I. and Borsos, Zalán and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and Sharifi, Matt and Zeghidour, Neil and Frank, Christian},
  
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {MusicLM: Generating Music From Text},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5579--5588},
  year={2021}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{hecater,
  title={CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks},
  author={He, Xuanli and Xu, Qiongkai and Zeng, Yi and Lyu, Lingjuan and Wu, Fangzhao and Li, Jiwei and Jia, Ruoxi},
  booktitle={Advances in Neural Information Processing Systems}
}

@inproceedings{he2022protecting,
  title={Protecting intellectual property of language generation apis with lexical watermark},
  author={He, Xuanli and Xu, Qiongkai and Lyu, Lingjuan and Wu, Fangzhao and Wang, Chenguang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10758--10766},
  year={2022}
}

@article{kirchenbauer2023watermark,
  title={A Watermark for Large Language Models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  journal={arXiv preprint arXiv:2301.10226},
  year={2023}
}

@inproceedings{kandpal2022deduplicating,
  title={Deduplicating training data mitigates privacy risks in language models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={10697--10707},
  year={2022},
  organization={PMLR}
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{allal2023santacoder,
  title={SantaCoder: don't reach for the stars!},
  author={Allal, Loubna Ben and Li, Raymond and Kocetkov, Denis and Mou, Chenghao and Akiki, Christopher and Ferrandis, Carlos Munoz and Muennighoff, Niklas and Mishra, Mayank and Gu, Alex and Dey, Manan and others},
  journal={arXiv preprint arXiv:2301.03988},
  year={2023}
}
@article{aghajanyan2023scaling,
  title={Scaling Laws for Generative Mixed-Modal Language Models},
  author={Aghajanyan, Armen and Yu, Lili and Conneau, Alexis and Hsu, Wei-Ning and Hambardzumyan, Karen and Zhang, Susan and Roller, Stephen and Goyal, Naman and Levy, Omer and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2301.03728},
  year={2023}
}

@article{cao2022ai,
  title={Ai in finance: challenges, techniques, and opportunities},
  author={Cao, Longbing},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={3},
  pages={1--38},
  year={2022},
  publisher={ACM New York, NY}
}

@article{borji2023categorical,
  title={A Categorical Archive of ChatGPT Failures},
  author={Borji, Ali},
  journal={arXiv preprint arXiv:2302.03494},
  year={2023}
}