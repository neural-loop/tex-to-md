\section{Introduction}
\label{Introduction}
Artificial Intelligence (AI) becomes necessary across a vast array of industries including health, manufacturing, agriculture, and banking \cite{AR1}. AI technologies have the potential to substantially transform society and offer various technical and societal benefits, which are expected to happen from high-level productivity and efficiency. In line with this, the ethical guidelines presented by the
independent high-level expert group on artificial intelligence (AI HLEG) highlights that \cite{AR2}:

\faLightbulb{ “\textit{AI is not an end in itself, but rather a promising means to increase human flourishing, thereby enhancing individual and societal well-being and the common good, as well as bringing progress and innovation.}”}

However, the promising advantages of AI technologies have been considered with worries that the complex and opaque systems might bring more social harms than benefits \cite{AR1}. People start thinking beyond the operational capabilities of AI technologies and investigating the ethical aspects of developing strong and potentially life consequential technologies. For example, US government and many private companies do not use the virtual implications of decision-making systems in health, criminal justice, employment, and creditworthiness without ensuring that these systems are not coded intentionally or unintentionally with structural biases \cite{AR1}.

Concomitant with advances in AI systems, we witness the ethical failure scenarios. For example, a high rate of unsuccessful job applications that were processed by the Amazon recruitment system was later found biased in analysis of the selection criteria against women applicants and triggered discriminatory issues \cite{AR3}. Since decisions and recommendations made by AI systems may undergone people lives, the need for developing pertinent policies and principles addressing the ethical aspects of AI systems is crucial. Otherwise, the harms caused by AI systems will jeopardize the control, safety, livelihood and rights of people. AI systems are not only concerned with technical efforts, but also need to consider the social, political, legal, and intellectual aspects. However, AI's current state of ethics is broadly unknown to the public, practitioners, policy, and lawmakers \cite{AR4}\cite{vallor2017artificial}.

Extensively, the ethically aligned AI system should meet the following three components through the entire life cycle \cite{AR2}: 1) compliance with all the applicable laws and regulations, 2) adherence to ethical principles and values, and 3) technical and social robustness.
To the best of our knowledge, there is a dearth of empirical study to uncover the above core components in the view of industrial practitioners and lawmakers. For instance, as will be elaborated in Section 7, Vakkuri et al. \cite{AR4} conducted a survey study to determine industrial perceptions based only on four AI ethics principles. Lu et al.\cite{AR12} conducted interviews with researchers and practitioners to understand the AI ethics principles implications and the motivation for rooting these principles in the design practices. Similarly, Leikas et al. \cite{AR5} mainly focused on AI ethics guidelines. Given the lack of empirical studies exploring principles and challenges associated with AI ethics, we strive to answer the following research questions:

\begin{tcolorbox} [sharp corners, boxrule=0.1mm,]
\small
\textbf{RQ1}:What are the practitioners' and lawmakers' insights on AI ethics principles and challenges?
\end{tcolorbox}

\textbf{\underline{Rationale}}: \textbf{RQ1} aims to digest the perceptions of practitioners and lawmakers to empirically evaluate the systematic literature review (SLR) study based identified AI ethics principles and challenges \cite{AR13}. The answer to \textbf{RQ1} provides a better understanding of the most common AI ethics principles and challenges with respect to practitioners and lawmakers point of views.

\begin{tcolorbox} [sharp corners, boxrule=0.1mm,]
\small
\textbf{RQ2}: What would be the severity impacts of identified challenges across the AI ethics principles?
\end{tcolorbox}

\textbf{\underline{Rationale}}: \textbf{RQ2} aims to measure the severity impacts of challenging factors across AI ethics principles. The answer to \textbf{RQ2} would inform practitioners for the most severe challenges before initiating the AI ethics activities.

\begin{tcolorbox} [sharp corners, boxrule=0.1mm,]
\small
\textbf{RQ3}: How these challenges and principles are differently perceived by practitioners and lawmakers?

\end{tcolorbox}

\textbf{\underline{Rationale}}: The empirical data were collected from two types of populations (practitioners and lawmakers). The answer to \textbf{RQ3} would portray a better understanding of significant differences between the opinion of targeted populations for AI ethics principles and challenges.

To address these RQs, we conducted a survey study by encapsulating the views and opinions of practitioners and lawmakers regarding AI ethics principles and challenges by collecting data from 99 respondents across 20 different countries.
