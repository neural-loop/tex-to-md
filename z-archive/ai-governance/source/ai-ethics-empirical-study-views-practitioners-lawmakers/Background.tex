\section{Background}
\label{Background}
Generally, the AI ethics is classified under the umbrella of applied ethics, which mainly concerns with ethical issues associated with developing and using the AI systems. It focuses on linking how an AI system could raise worries related to human autonomy, freedom in a democratic society, and quality of life. Ethical reflection across AI technologies could serve in achieving multiple societal purposes \cite{AR2}. For instance, it can stimulate focusing on innovations that aim to foster ethical values and bring collective well-being. Ethically aligned or trustworthy AI technologies can flourish sustainable well-being in society by bringing prosperity, wealth maximization, and value creation \cite{AR2}.    

It is vital to understand the development, deployment, and use of AI technologies to ensure that everyone can build a better future and live a thriving life in the AI-based world. However, the increasing popularity of AI systems has raised concerns such as reliability and impartiality of decision-making scenarios \cite{AR2}. We need to make sure that decision-making support of AI technologies must have an accountable process to ensure that their actions are ethically aligned with human values that should not be compromised \cite{AR2}.

In this regard, different organizations and technology giants developed committees to draft the AI ethics guidelines. Google and SAP presented the guidelines and policies to develop ethically aligned AI systems \cite{AR6}. Similarly, the Association of Computing Machinery (ACM), Access Now, and Amnesty International jointly proposed the principles and guidelines to develop an ethically mature AI system \cite{AR6}. In Europe, the (AI HLEG) guidelines are developed for promoting trustworthy AI \cite{AR2}. The Ethically Aligned Design (EAD) guidelines are presented by IEEE, consisting of a set of principles and recommendations that focus on the technical and ethical values of AI systems \cite{AR7}. In addition, the joint ISO/IEC international standard committee proposed the ISO/IEC JTC 1/SC 42 standard which covers the entire AI ecosystem, including trustworthiness, computational approach, governance, standardization, and social concerns \cite{AR8}.

However, various researchers claim that the extant AI ethics guidelines and principles are not effectively adopted in industrial settings. McNamara et al. \cite{AR9} conducted an empirical study to understand the influence of the ACM code of ethics in the software engineering decision-making process. Surprisingly, the study findings reveal that no evidence has been found that the ACM code of ethics regulate decision-making activities. Vakkuri et al. \cite{AR10} conducted multiple interviews to know the status of ethical practices in the domain of the AI industry. The study findings uncover the fact that various guidelines are available; however, their deployment in industrial domains are far from being mature. The gap between AI ethics research and practice remains an ongoing challenge. To bridge this gap, we previously conducted an SLR study to provide a comprehensive and state-of-the-art overview of AI ethics principles and challenges \cite{AR13}. This study is extended based on the SLR findings \cite{AR13} to provide empirical insights to know the significance of AI ethics principles, challenges, and their impact by encapsulating the views of AI practitioners and lawmakers.