\section{Concluding Remarks}
\label{sec:conclusion}

%This paper takes steps towards a transparency playbook that technologists can follow to support the legal and regulatory compliance needs of the users of the systems they build. We propose a stakeholder-first approach to transparency that, if followed, will help technologists design regulatory compliant systems.

If there is to be a positive, ethical future for the use of AI systems, there needs to be stakeholder-driven design for creating transparency algorithms --- and who better to lead this effort than technologists. Here we proposed a stakeholder-first approach that technologists can use to guide their design of transparent AI systems that are compliant with existing and proposed AI regulations. While there is still significant research that needs to be done in understanding how the transparency of AI systems can be most useful for stakeholders, and in the policy design of AI regulation, this paper aims to be a step in the right direction.  

%\subsection{Future Directions}

There are several important research steps that could be taken to extend this work. First, the stakeholder-first approach described here lays the foundation for creating a complete playbook to designing transparent systems. This playbook would be useful to a number of audiences including technologists, humans-in-the-loop, and policymakers. Second, a repository of examples and use cases of regulatory-compliant systems derived from this approach could be created, to act as a reference to technologists. 
