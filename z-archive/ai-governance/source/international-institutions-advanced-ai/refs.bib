
@misc{rees_g20_2023,
	title = {G20 must set up an international panel on technological change},
	url = {https://www.hindustantimes.com/opinion/g20-must-set-up-an-international-panel-on-technological-change-101679237287848.html},
	abstract = {The panel’s mandate will be to assess where we are and where we are headed in the future when it comes to “post-human technology”. Unlike IPCC, which deals with much longer time scales, IPTC will need to work much faster and nimbly. It seems to us that the G20 is the right-sized organisation for chartering such a panel and enabling its functioning.},
	language = {en},
	urldate = {2023-07-08},
	howpublished = {Hindustan Times},
	author = {Rees, Martin and Sondhi, Shivaji and VijayRaghavan, Krishnaswamy},
	month = mar,
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/6FPNC3R3/g20-must-set-up-an-international-panel-on-technological-change-101679237287848.html:text/html},
}

@article{chowdhury_ai_2023,
	title = {{AI} {Desperately} {Needs} {Global} {Oversight}},
	issn = {1059-1028},
	url = {https://www.wired.com/story/ai-desperately-needs-global-oversight/},
	abstract = {As ChatGPT and its ilk continue to spread, countries need an independent board to hold AI companies accountable and limit harms.},
	language = {en-US},
	urldate = {2023-07-09},
	journal = {Wired},
	author = {Chowdhury, Rumman},
	year = {2023},
	note = {Section: tags},
	keywords = {artificial intelligence, ethics, government, tech policy and law},
	file = {Snapshot:/Users/lewisho/Zotero/storage/PEE83TB7/ai-desperately-needs-global-oversight.html:text/html},
}

@misc{kakkad_new_2023,
	title = {A {New} {National} {Purpose}: {Innovation} {Can} {Power} the {Future} of {Britain}},
	shorttitle = {A {New} {National} {Purpose}},
	url = {https://www.institute.global/insights/politics-and-governance/new-national-purpose-innovation-can-power-future-britain},
	abstract = {A New National Purpose: Innovation Can Power the Future of Britain},
	language = {en-GB},
	urldate = {2023-07-09},
	author = {Kakkad, Jeegar and Macon-Cooney, Benedict and Northend, Jess and Phillips, James and Rajkumar, Nitarshan and Stanley, Luke and Westgarth, Tom},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/2XY78J6T/new-national-purpose-innovation-can-power-future-britain.html:text/html},
}

@misc{dubner_satya_nodate,
	title = {Satya {Nadella}’s {Intelligence} {Is} {Not} {Artificial}},
	url = {https://freakonomics.com/podcast/satya-nadellas-intelligence-is-not-artificial/},
	abstract = {Satya Nadella’s Intelligence Is Not Artificial - Freakonomics},
	language = {en},
	urldate = {2023-07-09},
	author = {Dubner, Stephen},
	file = {Snapshot:/Users/lewisho/Zotero/storage/U74DAPBC/satya-nadellas-intelligence-is-not-artificial.html:text/html},
}

@misc{noauthor_secretary-general_2023,
	title = {Secretary-{General} {Urges} {Broad} {Engagement} from {All} {Stakeholders} towards {United} {Nations} {Code} of {Conduct} for {Information} {Integrity} on {Digital} {Platforms} {\textbar} {UN} {Press}},
	url = {https://press.un.org/en/2023/sgsm21832.doc.htm},
	urldate = {2023-07-09},
	key = {un},
	howpublished = {United Nations},
	month = jun,
	year = {2023},
}

@misc{noauthor_elders_2023,
	title = {The {Elders} urge global co-operation to manage risks and share benefits of {AI}},
	url = {https://theelders.org/news/elders-urge-global-co-operation-manage-risks-and-share-benefits-ai},
	abstract = {The Elders today call on world leaders to work together urgently on the design of strong international governance, to allow all humanity to take advantage of the opportunities of Artificial Intelligence (AI), while limiting the enormous risks.},
	language = {en},
	key = {elders},
	urldate = {2023-07-09},
	howpublished = {The Elders},
	month = may,
	year = {2023},
}

@article{awokuse_stronger_2010,
	title = {Do {Stronger} {Intellectual} {Property} {Rights} {Protection} {Induce} {More} {Bilateral} {Trade}? {Evidence} from {China}'s {Imports}},
	volume = {38},
	shorttitle = {Do {Stronger} {Intellectual} {Property} {Rights} {Protection} {Induce} {More} {Bilateral} {Trade}?},
	abstract = {Most of the previous studies on the effect of IPR protection on international trade have been from the perspective of major industrialized nations. However, much of the current debate on the effects of IPR protection involves large developing countries with high threat of imitation. This study contributes to the literature by analyzing the impact of the strengthening of patent laws in China on its bilateral trade flows. We estimate the effects of patent rights protection on ChinaÃ¢Â€Â™s imports at the aggregate and detailed product categories for both OECD (developed) and non-OECD (developing) countries. The empirical results suggest that increased patent rights protection stimulate ChinaÃ¢Â€Â™s imports, particularly in the knowledge-intensive product categories. Furthermore, while the evidence in support of the market expansion effect is significant for imports from OECD countries, it is rather weak and mostly insignificant for imports from non-OECD countries.},
	number = {8},
	journal = {World Development},
	author = {Awokuse, Titus and Yin, Hong},
	year = {2010},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/4IWASB5L/Awokuse and Yin - 2008 - Do Stronger Intellectual Property Rights Protectio.pdf:application/pdf},
}

@article{vinuesa_role_2020,
	title = {The role of artificial intelligence in achieving the {Sustainable} {Development} {Goals}},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-14108-y},
	doi = {10.1038/s41467-019-14108-y},
	abstract = {The emergence of artificial intelligence (AI) and its progressively wider impact on many sectors requires an assessment of its effect on the achievement of the Sustainable Development Goals. Using a consensus-based expert elicitation process, we find that AI can enable the accomplishment of 134 targets across all the goals, but it may also inhibit 59 targets. However, current research foci overlook important aspects. The fast development of AI needs to be supported by the necessary regulatory insight and oversight for AI-based technologies to enable sustainable development. Failure to do so could result in gaps in transparency, safety, and ethical standards.},
	language = {en},
	number = {1},
	urldate = {2023-07-09},
	journal = {Nature Communications},
	author = {Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Felländer, Anna and Langhans, Simone Daniela and Tegmark, Max and Fuso Nerini, Francesco},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational science, Developing world, Energy efficiency},
	pages = {233},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/N6W8NI5A/Vinuesa et al. - 2020 - The role of artificial intelligence in achieving t.pdf:application/pdf},
}

@article{urbina_dual_2022,
	title = {Dual use of artificial-intelligence-powered drug discovery},
	volume = {4},
	copyright = {2022 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00465-9},
	doi = {10.1038/s42256-022-00465-9},
	abstract = {An international security conference explored how artificial intelligence (AI) technologies for drug discovery could be misused for de novo design of biochemical weapons. A thought experiment evolved into a computational proof.},
	language = {en},
	number = {3},
	urldate = {2023-07-09},
	journal = {Nature Machine Intelligence},
	author = {Urbina, Fabio and Lentzos, Filippa and Invernizzi, Cédric and Ekins, Sean},
	month = mar,
	year = {2022},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {Cheminformatics, Drug safety, Ethics, Software, Toxicology},
	pages = {189--191},
	file = {Accepted Version:/Users/lewisho/Zotero/storage/23RFNGTS/Urbina et al. - 2022 - Dual use of artificial-intelligence-powered drug d.pdf:application/pdf},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10–14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	language = {en},
	number = {7873},
	urldate = {2023-07-09},
	journal = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	month = aug,
	year = {2021},
	note = {Number: 7873
Publisher: Nature Publishing Group},
	keywords = {Computational biophysics, Machine learning, Protein structure predictions, Structural biology},
	pages = {583--589},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/5WYYQ9XJ/Jumper et al. - 2021 - Highly accurate protein structure prediction with .pdf:application/pdf},
}

@misc{noauthor_snyk_nodate,
	title = {Snyk},
	url = {https://snyk.io/},
	abstract = {Snyk helps software-driven businesses develop fast and stay secure. Continuously find and fix vulnerabilities for npm, Maven, NuGet, RubyGems, PyPI and more.},
	language = {en-US},
	urldate = {2023-07-09},
	howpublished = {Snyk},
	file = {Snapshot:/Users/lewisho/Zotero/storage/CJJSVS4I/snyk.io.html:text/html},
}

@misc{noauthor_codeql_nodate,
	title = {{CodeQL}},
	url = {https://codeql.github.com/},
	urldate = {2023-07-09},
	file = {CodeQL:/Users/lewisho/Zotero/storage/9S7YEZND/codeql.github.com.html:text/html},
}

@misc{steinhart_what_2023,
	title = {What will {GPT}-2030 look like?},
	url = {https://bounded-regret.ghost.io/what-will-gpt-2030-look-like/},
	abstract = {GPT-4 surprised many people with its abilities at coding, creative brainstorming, letter-writing, and other skills. How can we be less surprised by developments in machine learning? In this post, I’ll forecast the properties of large pretrained ML systems in 2030.},
	language = {en},
	urldate = {2023-07-09},
	howpublished = {Bounded Regret},
	author = {Steinhart, Jacob},
	month = jun,
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/4RF6YGSP/what-will-gpt-2030-look-like.html:text/html},
}

@article{bond_fake_2023,
	chapter = {Untangling Disinformation},
	title = {Fake viral images of an explosion at the {Pentagon} were probably created by {AI}},
	url = {https://www.npr.org/2023/05/22/1177590231/fake-viral-images-of-an-explosion-at-the-pentagon-were-probably-created-by-ai},
	abstract = {Authorities quickly confirmed that no explosion had taken place but the faked images spread on Twitter for a short time. The incident briefly sent the stock market lower.},
	language = {en},
	urldate = {2023-07-09},
	journal = {NPR},
	author = {Bond, Shannon},
	month = may,
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/NZFWWSE4/fake-viral-images-of-an-explosion-at-the-pentagon-were-probably-created-by-ai.html:text/html},
}

@misc{goldstein_generative_2023,
	title = {Generative {Language} {Models} and {Automated} {Influence} {Operations}: {Emerging} {Threats} and {Potential} {Mitigations}},
	shorttitle = {Generative {Language} {Models} and {Automated} {Influence} {Operations}},
	url = {http://arxiv.org/abs/2301.04246},
	doi = {10.48550/arXiv.2301.04246},
	abstract = {Generative language models have improved drastically, and can now produce realistic text outputs that are difficult to distinguish from human-written content. For malicious actors, these language models bring the promise of automating the creation of convincing and misleading text for use in influence operations. This report assesses how language models might change influence operations in the future, and what steps can be taken to mitigate this threat. We lay out possible changes to the actors, behaviors, and content of online influence operations, and provide a framework for stages of the language model-to-influence operations pipeline that mitigations could target (model construction, model access, content dissemination, and belief formation). While no reasonable mitigation can be expected to fully prevent the threat of AI-enabled influence operations, a combination of multiple mitigations may make an important difference.},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Goldstein, Josh A. and Sastry, Girish and Musser, Micah and DiResta, Renee and Gentzel, Matthew and Sedova, Katerina},
	month = jan,
	year = {2023},
	note = {arXiv:2301.04246 [cs]},
	keywords = {Computer Science - Computers and Society},
	annote = {Comment: 82 pages, 26 figures},
	file = {arXiv Fulltext PDF:/Users/lewisho/Zotero/storage/F6H62PNI/Goldstein et al. - 2023 - Generative Language Models and Automated Influence.pdf:application/pdf;arXiv.org Snapshot:/Users/lewisho/Zotero/storage/PJJZ2H2A/2301.html:text/html},
}

@misc{hendrycks_unsolved_2022,
	title = {Unsolved {Problems} in {ML} {Safety}},
	url = {http://arxiv.org/abs/2109.13916},
	abstract = {Machine learning (ML) systems are rapidly increasing in size, are acquiring new capabilities, and are increasingly deployed in high-stakes settings. As with other powerful technologies, safety for ML should be a leading research priority. In response to emerging safety challenges in ML, such as those introduced by recent large-scale models, we provide a new roadmap for ML Safety and refine the technical problems that the field needs to address. We present four problems ready for research, namely withstanding hazards ("Robustness"), identifying hazards ("Monitoring"), reducing inherent model hazards ("Alignment"), and reducing systemic hazards ("Systemic Safety"). Throughout, we clarify each problem's motivation and provide concrete research directions.},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
	month = jun,
	year = {2022},
	note = {arXiv:2109.13916 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: Position Paper},
	file = {arXiv.org Snapshot:/Users/lewisho/Zotero/storage/CE4B3F6B/2109.html:text/html;Full Text PDF:/Users/lewisho/Zotero/storage/VHVSEEQY/Hendrycks et al. - 2022 - Unsolved Problems in ML Safety.pdf:application/pdf},
}

@misc{amodei_concrete_2016,
	title = {Concrete {Problems} in {AI} {Safety}},
	url = {http://arxiv.org/abs/1606.06565},
	abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mané, Dan},
	month = jul,
	year = {2016},
	note = {arXiv:1606.06565 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 29 pages},
	file = {arXiv.org Snapshot:/Users/lewisho/Zotero/storage/SCY6S6WG/1606.html:text/html;Full Text PDF:/Users/lewisho/Zotero/storage/EHY55AQR/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf:application/pdf},
}

@misc{arnold_ai_2021,
	title = {{AI} {Accidents}: {An} {Emerging} {Threat}},
	shorttitle = {{AI} {Accidents}},
	url = {https://cset.georgetown.edu/publication/ai-accidents-an-emerging-threat/},
	abstract = {As modern machine learning systems become more widely used, the potential costs of malfunctions grow. This policy brief describes how trends we already see today—both in newly deployed artificial intelligence systems and in older technologies—show how damaging the AI accidents of the future could be. It describes a wide range of hypothetical but realistic scenarios to illustrate the risks of AI accidents and offers concrete policy suggestions to reduce these risks.},
	language = {en-US},
	urldate = {2023-07-09},
	howpublished = {Center for Security and Emerging Technology},
	author = {Arnold, Zachary and Toner, Helen},
	year = {2021},
	file = {Snapshot:/Users/lewisho/Zotero/storage/94NYZHQX/ai-accidents-an-emerging-threat.html:text/html},
}

@misc{noauthor_statement_2023,
	title = {Statement on {AI} {Risk}},
	url = {https://www.safe.ai/statement-on-ai-risk},
	abstract = {A statement jointly signed by a historic coalition of experts: “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.”},
	urldate = {2023-07-09},
	key = {center},
	howpublished = {Center for AI Safety},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/3V388YAB/statement-on-ai-risk.html:text/html},
}

@misc{hobbhahn_trends_2022,
	title = {Trends in {GPU} price-performance},
	url = {https://epochai.org/blog/trends-in-gpu-price-performance},
	abstract = {Using a dataset of 470 models of graphics processing units released between 2006 and 2021, we find that the amount of floating-point operations/second per \$ doubles every {\textasciitilde}2.5 years.},
	language = {en},
	urldate = {2023-07-09},
	howpublished = {Epoch},
	author = {Hobbhahn, Marius},
	year = {2022},
	file = {Snapshot:/Users/lewisho/Zotero/storage/H2IN66TH/trends-in-gpu-price-performance.html:text/html},
}

@misc{erdil_algorithmic_2023,
	title = {Algorithmic {Progress} in {Computer} {Vision}},
	url = {https://arxiv.org/abs/2212.05153},
	abstract = {We use a dataset of over a hundred computer vision models from the last decade to investigate how better algorithms and architectures have enabled researchers to use compute and data more efficiently. We find that every 9 months, the introduction of better algorithms contribute the equivalent of a doubling of compute budgets.},
	language = {en},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Erdil, Ege and Besiroglu, Tamay},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/B8V3SDHB/revisiting-algorithmic-progress.html:text/html},
}

@article{toner_illusion_2023,
	title = {The {Illusion} of {China}’s {AI} {Prowess}},
	issn = {0015-7120},
	url = {https://www.foreignaffairs.com/china/illusion-chinas-ai-prowess-regulation},
	abstract = {Regulating AI will not set America back in the technology race.},
	language = {en-US},
	urldate = {2023-07-09},
	journal = {Foreign Affairs},
	author = {Toner, Helen and Xiao, Jenny and Ding, Jeffrey},
	month = jun,
	year = {2023},
	keywords = {Artificial Intelligence, Automation, China, East Asia, Law, Politics \& Society, Science \& Technology, United States},
	file = {Snapshot:/Users/lewisho/Zotero/storage/RYPKNIHC/illusion-chinas-ai-prowess-regulation.html:text/html},
}

@misc{noauthor_netherlands_2023,
	title = {The {Netherlands} joins the {U}.{S}. in restricting semiconductor exports to {China}},
	url = {https://www.allenovery.com/en-gb/global/news-and-insights/publications/the-netherlands-joins-the-us-in-restricting-semiconductor-exports-to-china},
	abstract = {In January 2023, the Netherlands and Japan agreed with the United States to impose controls on the export of certain semiconductors and related products to China.  This followed a push by the Biden Administration to ensure the effectiveness of related U.S. export controls that were introduced in October 2022.},
	language = {en},
	key = {allen},
	urldate = {2023-07-09},
	howpublished = {Allen Overy},
	month = mar,
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/DNLPEWUY/the-netherlands-joins-the-us-in-restricting-semiconductor-exports-to-china.html:text/html},
}

@misc{noauthor_pm_2023,
	title = {{PM} urges tech leaders to grasp generational opportunities and challenges of {AI}},
	url = {https://www.gov.uk/government/news/pm-urges-tech-leaders-to-grasp-generational-opportunities-and-challenges-of-ai},
	abstract = {The UK must act quickly if we want to retain our position as one of the world’s tech capitals, Prime Minister Rishi Sunak will tell tech leaders today [Monday 12 June].},
	language = {en},
	urldate = {2023-07-09},
	howpublished = {GOV.UK},
	key = {govuk},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/NVM2G3KI/pm-urges-tech-leaders-to-grasp-generational-opportunities-and-challenges-of-ai.html:text/html},
}

@misc{singh_anthropics_2023,
	title = {Anthropic's \${5B}, 4-year plan to take on {OpenAI}},
	url = {https://techcrunch.com/2023/04/06/anthropics-5b-4-year-plan-to-take-on-openai/},
	abstract = {AI research startup Anthropic aims to raise as much as \$5 billion over the next two years to take on rival OpenAI.},
	language = {en-US},
	urldate = {2023-07-09},
	howpublished = {TechCrunch},
	author = {Singh, Devin Coldewey {and} Manish, Kyle Wiggers},
	month = apr,
	year = {2023},
}

@article{veale_ai_2023,
	title = {{AI} and {Global} {Governance}: {Modalities}, {Rationales}, {Tensions}},
	volume = {19},
	language = {en},
	journal = {Annual Review of Law and Social Science},
	author = {Veale, Michael and Matus, Kira and Gorwa, Robert},
	year = {2023},
	file = {Veale et al. - 2023 - AI and Global Governance Modalities, Rationales, .pdf:/Users/lewisho/Zotero/storage/4E2INQF9/Veale et al. - 2023 - AI and Global Governance Modalities, Rationales, .pdf:application/pdf},
}

@misc{noauthor_preparing_nodate,
	title = {Preparing {Reports} — {IPCC}},
	url = {https://www.ipcc.ch/about/preparingreports/},
	urldate = {2023-07-09},
	file = {Snapshot:/Users/lewisho/Zotero/storage/NDQZCNMN/preparingreports.html:text/html},
}

@article{shaw_relevant_2004,
	title = {Relevant {But} {Not} {Prescriptive}: {Science} {Policy} {Models} within the {IPCC}},
	volume = {48},
	shorttitle = {Relevant {But} {Not} {Prescriptive}},
	doi = {10.5840/philtoday200448Supplement9},
	abstract = {The Intergovernmental Panel on Climate Change (IPCC) represents perhaps the largest example of ‘mandated science’ ever undertaken. It activities therefore raise a number of critical issues concerning the science/society interface. While previous studies of the IPCC have focused on the scientific credibility of its findings, this paper will examine the credibility of the process and protocols employed to assess “policy relevant but not policy prescriptive scientific information”. In particular we will examine two unique devices used in the IPCC: the Summary for Policymakers (SPM) and the Policy Relevant Scientific Questions (PRSQ). It will be argued that, despite unhappiness on the part of some of the scientific participants, the negotiation of meaning given rise to in these processes represents a credible and useful way to bridge the science/policy divide and in turn provides insights into ways to bridge the larger issues of the role of science in society.},
	journal = {Philosophy Today},
	author = {Shaw, Alison and Robinson, John},
	month = jan,
	year = {2004},
	pages = {84--95},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/XV3TGF7A/Shaw and Robinson - 2004 - Relevant But Not Prescriptive Science Policy Mode.pdf:application/pdf},
}

@techreport{toivanen_significance_2017,
	title = {The {Significance} of {Strategic} {Foresight} in {Verification} {Technologies}: {A} {Case} {Study} of the {INF} {Treaty}},
	shorttitle = {The {Significance} of {Strategic} {Foresight} in {Verification} {Technologies}},
	url = {https://www.osti.gov/servlets/purl/1502006/},
	language = {en},
	number = {LLNL-TR--738786, 1502006, 892173},
	urldate = {2023-07-09},
	author = {Toivanen, Henrietta},
	month = sep,
	year = {2017},
	doi = {10.2172/1502006},
	pages = {LLNL--TR--738786, 1502006, 892173},
	file = {Toivanen - 2017 - The Significance of Strategic Foresight in Verific.pdf:/Users/lewisho/Zotero/storage/3LNAJGHV/Toivanen - 2017 - The Significance of Strategic Foresight in Verific.pdf:application/pdf},
}

@misc{shavit_what_2023,
	title = {What does it take to catch a {Chinchilla}? {Verifying} {Rules} on {Large}-{Scale} {Neural} {Network} {Training} via {Compute} {Monitoring}},
	shorttitle = {What does it take to catch a {Chinchilla}?},
	url = {http://arxiv.org/abs/2303.11341},
	doi = {10.48550/arXiv.2303.11341},
	abstract = {As advanced machine learning systems' capabilities begin to play a significant role in geopolitics and societal order, it may become imperative that (1) governments be able to enforce rules on the development of advanced ML systems within their borders, and (2) countries be able to verify each other's compliance with potential future international agreements on advanced ML development. This work analyzes one mechanism to achieve this, by monitoring the computing hardware used for large-scale NN training. The framework's primary goal is to provide governments high confidence that no actor uses large quantities of specialized ML chips to execute a training run in violation of agreed rules. At the same time, the system does not curtail the use of consumer computing devices, and maintains the privacy and confidentiality of ML practitioners' models, data, and hyperparameters. The system consists of interventions at three stages: (1) using on-chip firmware to occasionally save snapshots of the the neural network weights stored in device memory, in a form that an inspector could later retrieve; (2) saving sufficient information about each training run to prove to inspectors the details of the training run that had resulted in the snapshotted weights; and (3) monitoring the chip supply chain to ensure that no actor can avoid discovery by amassing a large quantity of un-tracked chips. The proposed design decomposes the ML training rule verification problem into a series of narrow technical challenges, including a new variant of the Proof-of-Learning problem [Jia et al. '21].},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Shavit, Yonadav},
	month = may,
	year = {2023},
	note = {arXiv:2303.11341 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/lewisho/Zotero/storage/NDWX7245/Shavit - 2023 - What does it take to catch a Chinchilla Verifying.pdf:application/pdf;arXiv.org Snapshot:/Users/lewisho/Zotero/storage/M8DR2UAH/2303.html:text/html},
}

@misc{noauthor_memorandum_2008,
	title = {Memorandum by the {Financial} {Action} {Task} {Force} ({FATF}) {Secretariat}},
	url = {https://publications.parliament.uk/pa/ld200809/ldselect/ldeucom/132/132we08.htm},
	urldate = {2023-07-09},
	key = {UK},
	howpublished = {UK Parliament},
	year = {2008},
	file = {House of Lords - European Union Committee - Written Evidence:/Users/lewisho/Zotero/storage/BSPYLD94/132we08.html:text/html},
}

@book{gallagher_politics_1999,
	title = {The {Politics} of {Verification}},
	urldate = {2023-07-09},
	publisher = {Johns Hopkins University Press},
	author = {Gallagher, Nancy},
	year = {1999},
	file = {The Politics of Verification - Nancy W. Gallagher - Google Books:/Users/lewisho/Zotero/storage/9VN3U3UR/The_Politics_of_Verification.html:text/html},
}

@article{spirling_why_2023,
	title = {Why open-source generative {AI} models are an ethical way forward for science},
	volume = {616},
	copyright = {2023 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-023-01295-4},
	doi = {10.1038/d41586-023-01295-4},
	abstract = {Researchers should avoid the lure of proprietary models and develop transparent large language models to ensure reproducibility.},
	language = {en},
	number = {7957},
	urldate = {2023-07-09},
	journal = {Nature},
	author = {Spirling, Arthur},
	month = apr,
	year = {2023},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7957
Publisher: Nature Publishing Group
Subject\_term: Ethics, Machine learning, Technology, Scientific community},
	keywords = {Ethics, Machine learning, Scientific community, Technology},
	pages = {413--413},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/G8HM658L/Spirling - 2023 - Why open-source generative AI models are an ethica.pdf:application/pdf;Snapshot:/Users/lewisho/Zotero/storage/ECXTQYTH/d41586-023-01295-4.html:text/html},
}

@misc{rauf_atoms_2015,
	title = {From ‘{Atoms} for {Peace}’ to an {IAEA} {Nuclear} {Fuel} {Bank} {\textbar} {Arms} {Control} {Association}},
	url = {https://www.armscontrol.org/act/2015-10/features/%E2%80%98atoms-peace%E2%80%99-iaea-nuclear-fuel-bank},
	urldate = {2023-07-09},
	howpublished = {Arms Control Association},
	author = {Rauf, Tariq},
	month = oct,
	year = {2015},
	file = {From ‘Atoms for Peace’ to an IAEA Nuclear Fuel Bank | Arms Control Association:/Users/lewisho/Zotero/storage/MRN8K829/‘atoms-peace’-iaea-nuclear-fuel-bank.html:text/html},
}

@article{mohamed_decolonial_2020,
	title = {Decolonial {AI}: {Decolonial} {Theory} as {Sociotechnical} {Foresight} in {Artificial} {Intelligence}},
	volume = {33},
	issn = {2210-5441},
	shorttitle = {Decolonial {AI}},
	url = {https://doi.org/10.1007/s13347-020-00405-8},
	doi = {10.1007/s13347-020-00405-8},
	abstract = {This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. While the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us, ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all.},
	language = {en},
	number = {4},
	urldate = {2023-07-09},
	journal = {Philosophy \& Technology},
	author = {Mohamed, Shakir and Png, Marie-Therese and Isaac, William},
	month = dec,
	year = {2020},
	keywords = {Affective community, Artificial intelligence, Coloniality, Critical technical practice, Decolonisation, Intercultural ethics, Sociotechnical foresight},
	pages = {659--684},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/2WQWENKJ/Mohamed et al. - 2020 - Decolonial AI Decolonial Theory as Sociotechnical.pdf:application/pdf},
}

@misc{noauthor_what_2020,
	title = {What is an {Advance} {Market} {Commitment} and how could it help beat {COVID}-19? {\textbar} {Gavi}, the {Vaccine} {Alliance}},
	shorttitle = {What is an {Advance} {Market} {Commitment} and how could it help beat {COVID}-19?},
	url = {https://www.gavi.org/vaccineswork/what-advance-market-commitment-and-how-could-it-help-beat-covid-19},
	language = {en},
	key = {Gavi},
	urldate = {2023-07-09},
	howpublished = {Gavi, the Vaccine Alliance},
	year = {2020},
	file = {Snapshot:/Users/lewisho/Zotero/storage/WAGIS4LX/what-advance-market-commitment-and-how-could-it-help-beat-covid-19.html:text/html},
}

@inproceedings{cihon_should_2020,
	address = {New York NY USA},
	title = {Should {Artificial} {Intelligence} {Governance} be {Centralised}?: {Design} {Lessons} from {History}},
	isbn = {978-1-4503-7110-0},
	shorttitle = {Should {Artificial} {Intelligence} {Governance} be {Centralised}?},
	url = {https://dl.acm.org/doi/10.1145/3375627.3375857},
	doi = {10.1145/3375627.3375857},
	abstract = {The invention of atomic energy posed a novel global challenge: could the technology be controlled to avoid destructive uses and an existentially dangerous arms race while permitting the broad sharing of its benefits? From 1944 onwards, scientists, policymakers, and other t echnical specialists began to confront this challenge and explored policy options for dealing with the impact of nuclear technology. We focus on the years 1944 to 1951 and review this period for lessons for the governance of powerful technologies, and find the following: Radical schemes for international control can get broad support when confronted by existentially dangerous technologies, but this support can be tenuous and cynical. Secrecy is likely to play an important, and perhaps harmful, role. The public sphere may be an important source of influence, both in general and in particular in favor of cooperation, but also one that is manipulable and poorly informed. Technical experts may play a critical role, but need to be politically savvy. Overall, policymaking may look more like “muddling through” than clear-eyed grand strategy. Cooperation may be risky, and there may be many obstacles to success.},
	language = {en},
	urldate = {2023-07-09},
	booktitle = {Proceedings of the {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Cihon, Peter and Maas, Matthijs M. and Kemp, Luke},
	month = feb,
	year = {2020},
	pages = {228--234},
	file = {Cihon et al. - 2020 - Should Artificial Intelligence Governance be Centr.pdf:/Users/lewisho/Zotero/storage/NP3Z6SLX/Cihon et al. - 2020 - Should Artificial Intelligence Governance be Centr.pdf:application/pdf},
}

@misc{taori_alpaca_2023,
	title = {Alpaca: {A} {Strong}, {Replicable} {Instruction}-{Following} {Model}},
	url = {https://crfm.stanford.edu/2023/03/13/alpaca.html},
	urldate = {2023-07-09},
	howpublished = {Stanford CRFM},
	author = {Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori},
	month = mar,
	year = {2023},
}

@article{nast_maori_nodate,
	title = {Māori are trying to save their language from {Big} {Tech}},
	issn = {1357-0978},
	url = {https://www.wired.co.uk/article/maori-language-tech},
	abstract = {Te Hiku Media gathered huge swathes of Māori language data. Corporates are now trying to get the rights to it},
	language = {en-GB},
	urldate = {2023-07-09},
	howpublished = {Wired UK},
	author = {Nast, Condé},
	note = {Section: tags},
	keywords = {artificial intelligence, data, internet culture},
}

@misc{noauthor_unfccc_nodate,
	title = {{UNFCCC} {Technology} {Mechanism}},
	url = {https://unfccc.int/ttclear/support/technology-mechanism.html},
	urldate = {2023-07-09},
	key = {UNFCCC},
	howpublished = {UNFCCC},
	file = {Technology Mechanism:/Users/lewisho/Zotero/storage/66Y4EXPH/technology-mechanism.html:text/html},
}

@misc{hammond_opinion_2023,
	title = {Opinion {\textbar} {We} {Need} a {Manhattan} {Project} for {AI} {Safety}},
	url = {https://www.politico.com/news/magazine/2023/05/08/manhattan-project-for-ai-safety-00095779},
	abstract = {AI presents an enormous threat. It deserves an enormous response.},
	language = {en},
	urldate = {2023-07-09},
	howpublished = {POLITICO},
	author = {Hammond, Samuel},
	month = may,
	year = {2023},
}

@misc{shevlane_structured_2022,
	title = {Structured access: an emerging paradigm for safe {AI} deployment},
	shorttitle = {Structured access},
	url = {http://arxiv.org/abs/2201.05159},
	doi = {10.48550/arXiv.2201.05159},
	abstract = {Structured access is an emerging paradigm for the safe deployment of artificial intelligence (AI). Instead of openly disseminating AI systems, developers facilitate controlled, arm's length interactions with their AI systems. The aim is to prevent dangerous AI capabilities from being widely accessible, whilst preserving access to AI capabilities that can be used safely. The developer must both restrict how the AI system can be used, and prevent the user from circumventing these restrictions through modification or reverse engineering of the AI system. Structured access is most effective when implemented through cloud-based AI services, rather than disseminating AI software that runs locally on users' hardware. Cloud-based interfaces provide the AI developer greater scope for controlling how the AI system is used, and for protecting against unauthorized modifications to the system's design. This chapter expands the discussion of "publication norms" in the AI community, which to date has focused on the question of how the informational content of AI research projects should be disseminated (e.g., code and models). Although this is an important question, there are limits to what can be achieved through the control of information flows. Structured access views AI software not only as information that can be shared but also as a tool with which users can have arm's length interactions. There are early examples of structured access being practiced by AI developers, but there is much room for further development, both in the functionality of cloud-based interfaces and in the wider institutional framework.},
	urldate = {2023-07-09},
	publisher = {arXiv},
	author = {Shevlane, Toby},
	month = apr,
	year = {2022},
	note = {arXiv:2201.05159 [cs]},
	keywords = {68T99, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Software Engineering},
	annote = {Comment: 28 pages},
	file = {arXiv Fulltext PDF:/Users/lewisho/Zotero/storage/7QQZEKMD/Shevlane - 2022 - Structured access an emerging paradigm for safe A.pdf:application/pdf;arXiv.org Snapshot:/Users/lewisho/Zotero/storage/ZMVHS2DK/2201.html:text/html},
}

@techreport{schmidt_nscai_2021,
	title = {{NSCAI} {Final} {Report}},
	url = {https://www.nscai.gov/2021-final-report/},
	language = {en-US},
	urldate = {2023-07-09},
	institution = {National Security Commission on Artificial Intelligence},
	author = {Schmidt, Eric and Work, Robert and Catz, Safra and Horvitz, Eric and Chien, Steve and Jassy, Andrew and Clyburn, Mignon and Louie, Gilman and Darby, Chris and Mark, William and Ford, Kenneth and Matheny, Jason and Griffiths, Jose-Marie and McFarland, Katharina and Andrew Moore},
	year = {2021},
	file = {Snapshot:/Users/lewisho/Zotero/storage/RSRCPCBP/2021-final-report.html:text/html},
}

@article{diaz_ipbes_2015,
	series = {Open {Issue}},
	title = {The {IPBES} {Conceptual} {Framework} — connecting nature and people},
	volume = {14},
	issn = {1877-3435},
	url = {https://www.sciencedirect.com/science/article/pii/S187734351400116X},
	doi = {10.1016/j.cosust.2014.11.002},
	abstract = {The first public product of the Intergovernmental Platform on Biodiversity and Ecosystem Services (IPBES) is its Conceptual Framework. This conceptual and analytical tool, presented here in detail, will underpin all IPBES functions and provide structure and comparability to the syntheses that IPBES will produce at different spatial scales, on different themes, and in different regions. Salient innovative aspects of the IPBES Conceptual Framework are its transparent and participatory construction process and its explicit consideration of diverse scientific disciplines, stakeholders, and knowledge systems, including indigenous and local knowledge. Because the focus on co-construction of integrative knowledge is shared by an increasing number of initiatives worldwide, this framework should be useful beyond IPBES, for the wider research and knowledge-policy communities working on the links between nature and people, such as natural, social and engineering scientists, policy-makers at different levels, and decision-makers in different sectors of society.},
	language = {en},
	urldate = {2023-07-09},
	journal = {Current Opinion in Environmental Sustainability},
	author = {Díaz, Sandra and Demissew, Sebsebe and Carabias, Julia and Joly, Carlos and Lonsdale, Mark and Ash, Neville and Larigauderie, Anne and Adhikari, Jay Ram and Arico, Salvatore and Báldi, András and Bartuska, Ann and Baste, Ivar Andreas and Bilgin, Adem and Brondizio, Eduardo and Chan, Kai MA and Figueroa, Viviana Elsa and Duraiappah, Anantha and Fischer, Markus and Hill, Rosemary and Koetz, Thomas and Leadley, Paul and Lyver, Philip and Mace, Georgina M and Martin-Lopez, Berta and Okumura, Michiko and Pacheco, Diego and Pascual, Unai and Pérez, Edgar Selvin and Reyers, Belinda and Roth, Eva and Saito, Osamu and Scholes, Robert John and Sharma, Nalini and Tallis, Heather and Thaman, Randolph and Watson, Robert and Yahara, Tetsukazu and Hamid, Zakri Abdul and Akosim, Callistus and Al-Hafedh, Yousef and Allahverdiyev, Rashad and Amankwah, Edward and Asah, Stanley T and Asfaw, Zemede and Bartus, Gabor and Brooks, L Anathea and Caillaux, Jorge and Dalle, Gemedo and Darnaedi, Dedy and Driver, Amanda and Erpul, Gunay and Escobar-Eyzaguirre, Pablo and Failler, Pierre and Fouda, Ali Moustafa Mokhtar and Fu, Bojie and Gundimeda, Haripriya and Hashimoto, Shizuka and Homer, Floyd and Lavorel, Sandra and Lichtenstein, Gabriela and Mala, William Armand and Mandivenyi, Wadzanayi and Matczak, Piotr and Mbizvo, Carmel and Mehrdadi, Mehrasa and Metzger, Jean Paul and Mikissa, Jean Bruno and Moller, Henrik and Mooney, Harold A and Mumby, Peter and Nagendra, Harini and Nesshover, Carsten and Oteng-Yeboah, Alfred Apau and Pataki, György and Roué, Marie and Rubis, Jennifer and Schultz, Maria and Smith, Peggy and Sumaila, Rashid and Takeuchi, Kazuhiko and Thomas, Spencer and Verma, Madhu and Yeo-Chang, Youn and Zlatanova, Diana},
	month = jun,
	year = {2015},
	pages = {1--16},
	file = {ScienceDirect Full Text PDF:/Users/lewisho/Zotero/storage/WGI2L4BQ/Díaz et al. - 2015 - The IPBES Conceptual Framework — connecting nature.pdf:application/pdf;ScienceDirect Snapshot:/Users/lewisho/Zotero/storage/IKQJMX29/S187734351400116X.html:text/html},
}

@article{maya_capacity_2010,
	title = {Capacity {Building} for {Technology} {Transfer} in the {African} {Context}: {Priorities} and {Strategies}},
	journal = {UNFCC},
	author = {Maya, Shakespeare},
	year = {2010},
}

@misc{hogarth_we_2023,
	title = {We must slow down the race to {God}-like {AI} {\textbar} {Financial} {Times}},
	url = {https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2},
	urldate = {2023-07-09},
	journal = {Financial Times},
	author = {Hogarth, Ian},
	year = {2023},
	file = {We must slow down the race to God-like AI | Financial Times:/Users/lewisho/Zotero/storage/8LEX33R2/03895dc4-a3b7-481e-95cc-336a524f2ac2.html:text/html},
}

@misc{shimony_chatting_2023,
	title = {Chatting {Our} {Way} {Into} {Creating} a {Polymorphic} {Malware}},
	url = {https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware},
	abstract = {Abstract ChatGPT took the world by storm being released less than two months ago, it has become prominent and is used everywhere, for a wide variety of tasks – from automation tasks to the...},
	language = {en},
	urldate = {2023-07-09},
	author = {Shimony, Eran and Tsarfati, Omar},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/QWM6KXIK/chatting-our-way-into-creating-a-polymorphic-malware.html:text/html},
}

@misc{anderljung_frontier_2023,
	title = {Frontier {AI} {Regulation}: {Managing} {Emerging} {Risks} to {Public} {Safety}},
	publisher = {arXiv},
	author = {Anderljung, Markus and Barnhart, Joslyn and Leung, Jade and Korinek, Anton and O'Keefe, Cullen and Whittlestone, Jess and Avin, Shahar and Brundage, Miles and Bullock, Justin and Cass-Beggs, Duncan and Chang, Ben and Collins, Tantum and Fist, Tim and Hadfield, Gillian and Hayes, Alan and Ho, Lewis and Hooker, Sarah and Horvitz, Eric and Kolt, Noam and Schuett, Jonas and Shavit, Yonadav and Siddarth, Divya and Trager, Robert and Wolf, Kevin},
	year = {2023},
}

@misc{mailhe_why_2018,
	title = {Why {We} {Need} an {Intergovernmental} {Panel} for {Artificial} {Intelligence} - {Our} {World}},
	url = {https://ourworld.unu.edu/en/why-we-need-an-intergovernmental-panel-for-artificial-intelligence},
	abstract = {Global governance has a role to play in developing standards that balance the benefits and risks of deploying AI technologies, and that ensure citizens are aware of their rights and protections.},
	urldate = {2023-07-09},
	author = {Mailhe, Nicolas},
	year = {2018},
	file = {Snapshot:/Users/lewisho/Zotero/storage/7LJ6XUZX/why-we-need-an-intergovernmental-panel-for-artificial-intelligence.html:text/html},
}

@article{noauthor_editorial_2023,
	title = {Editorial: {Stop} talking about tomorrow’s {AI} doomsday when {AI} poses risks today},
	volume = {618},
	copyright = {2023 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-023-02094-7},
	abstract = {Talk of artificial intelligence destroying humanity plays into the tech companies’ agenda, and hinders effective regulation of the societal harms AI is causing right now.},
	language = {en},
	number = {7967},
	urldate = {2023-07-09},
	journal = {Nature},
	key = {Nature},
	month = jun,
	year = {2023},
	note = {Bandiera\_abtest: a
Cg\_type: Editorial
Number: 7967
Publisher: Nature Publishing Group
Subject\_term: Machine learning, Authorship, Ethics},
	keywords = {Authorship, Ethics, Machine learning},
	pages = {885--886},
	file = {Full Text PDF:/Users/lewisho/Zotero/storage/QDRA6KG4/2023 - Stop talking about tomorrow’s AI doomsday when AI .pdf:application/pdf;Snapshot:/Users/lewisho/Zotero/storage/FWNNPINZ/d41586-023-02094-7.html:text/html},
}

@misc{altman_governance_2023,
	title = {Governance of superintelligence},
	url = {https://openai.com/blog/governance-of-superintelligence},
	abstract = {Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically more capable than even AGI.},
	language = {en-US},
	urldate = {2023-07-09},
	howpublished = {OpenAI},
	author = {Altman, Sam and Brockman, Greg and Sutskever, Ilya},
	year = {2023},
	file = {Snapshot:/Users/lewisho/Zotero/storage/YVWQ33J3/governance-of-superintelligence.html:text/html},
}

@article{marcus_world_2023,
	title = {The world needs an international agency for artificial intelligence, say two {AI} experts},
	issn = {0013-0613},
	url = {https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts},
	urldate = {2023-07-09},
	journal = {The Economist},
	author = {Marcus, Gary and Reuel, Anka},
	year = {2023},
	file = {The Economist Snapshot:/Users/lewisho/Zotero/storage/TGX3783P/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts.html:text/html},
}

@article{brundage_computing_nodate,
	title = {Computing {Power} and the {Governance} of {Artificial} {Intelligence}},
	author = {Brundage, Miles and Sastry, Girish and Heim, Lennart and Belfield, Haydn and Hazell, Julian and Anderljung, Markus and Avin, Shahar and Leung, Jade and O'Keefe, Cullen and Ngo, Richard},
}

@article{jordan_international_nodate,
	title = {International {Governance} of {Advanced} {AI}},
	author = {Jordan, Richard and Emery-Xu, Nicholas and Trager, Robert},
}

@inproceedings{cihon_should_2020-1,
	address = {New York NY USA},
	title = {Should {Artificial} {Intelligence} {Governance} be {Centralised}?: {Design} {Lessons} from {History}},
	isbn = {978-1-4503-7110-0},
	shorttitle = {Should {Artificial} {Intelligence} {Governance} be {Centralised}?},
	url = {https://dl.acm.org/doi/10.1145/3375627.3375857},
	doi = {10.1145/3375627.3375857},
	abstract = {The invention of atomic energy posed a novel global challenge: could the technology be controlled to avoid destructive uses and an existentially dangerous arms race while permitting the broad sharing of its benefits? From 1944 onwards, scientists, policymakers, and other t echnical specialists began to confront this challenge and explored policy options for dealing with the impact of nuclear technology. We focus on the years 1944 to 1951 and review this period for lessons for the governance of powerful technologies, and find the following: Radical schemes for international control can get broad support when confronted by existentially dangerous technologies, but this support can be tenuous and cynical. Secrecy is likely to play an important, and perhaps harmful, role. The public sphere may be an important source of influence, both in general and in particular in favor of cooperation, but also one that is manipulable and poorly informed. Technical experts may play a critical role, but need to be politically savvy. Overall, policymaking may look more like “muddling through” than clear-eyed grand strategy. Cooperation may be risky, and there may be many obstacles to success.},
	language = {en},
	urldate = {2023-07-09},
	booktitle = {Proceedings of the {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Cihon, Peter and Maas, Matthijs M. and Kemp, Luke},
	month = feb,
	year = {2020},
	pages = {228--234},
	file = {Cihon et al. - 2020 - Should Artificial Intelligence Governance be Centr.pdf:/Users/lewisho/Zotero/storage/WTP9A7TS/Cihon et al. - 2020 - Should Artificial Intelligence Governance be Centr.pdf:application/pdf},
}

@article{zaidi_international_2019,
	title = {International {Control} of {Powerful} {Technology}: {Lessons} from the {Baruch} {Plan} for {Nuclear} {Weapons}},
	url = {https://www.fhi.ox.ac.uk/wp-content/uploads/2021/03/International-Control-of-Powerful-Technology-Lessons-from-the-Baruch-Plan-Zaidi-Dafoe-2021.pdf},
	journal = {Working Paper},
	author = {Zaidi, Waqar and Dafoe, Allan},
	year = {2019},
}

@misc{le_gall_how_2021,
	title = {How {CERN} intellectual property helps entrepreneurship},
	url = {https://home.cern/news/news/knowledge-sharing/how-cern-intellectual-property-helps-entrepreneurship},
	abstract = {The novel technologies and expertise developed at CERN can be applied to fields other than high-energy physics. World Intellectual Property Day, observed annually on 26 April, is an opportunity to highlight how intellectual property (IP) is at the core of transferring unique CERN knowledge to its industrial and institutional partners, from large, long-standing companies to recent start-ups. In order to share its knowledge, CERN encourages the creation of spin-offs – companies based, partially or wholly, on CERN technologies – and has adopted a dedicated spin-off policy in 2018. One such company is PlanetWatch. Founded in 2020, this spin-off bases its air-quality data-analysis activities on C2MON, a data-acquisition framework developed at CERN. CERN also offers special licensing opportunities to promote the use of CERN technology in existing start-ups. These technologies range from innovative detector technologies to complex software, from radiation-hardened components to robotic platforms. As Marco Silari, section leader in the Radiation Protection group, explains “CERN technology can become much more than originally planned”. Together with his team, he developed several detector technologies now used by start-ups and companies around Europe. The complete list of current start-ups \& spin-offs using CERN technology \& know-how is available here. Depending on the nature of the technology and its application, it may benefit from Open Source licencing. This is the case for the White Rabbit technology – a tool used to provide control and data-acquisition systems with sub-nanosecond accuracy and a synchronisation precision of a few picoseconds – available on CERN’s Open Hardware Repository under the CERN Open Hardware Licence, to a large user community. Intellectual property enables successful knowledge transfer, ensuring the application of CERN technology and expertise in a way that aligns with CERN’s values, and maximises their societal impact. CERN’s policy is to disseminate its technologies as widely as possible to industrial and institutional partners within its Member States. Find out more about CERN’s management of Intellectual Property: https://kt.cern/activities-services/intellectual-property-management},
	language = {en},
	urldate = {2023-07-10},
	howpublished = {CERN},
	author = {Le Gall, Antoine},
	year = {2021},
	file = {Snapshot:/Users/lewisho/Zotero/storage/9ZQISEJH/how-cern-intellectual-property-helps-entrepreneurship.html:text/html},
}
