
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@Article{Abril07,
  author        = "Patricia S. Abril and Robert Plant",
  title         = "The patent holder's dilemma: Buy, sell, or troll?",
  journal       = "Communications of the ACM",
  volume        = "50",
  number        = "1",
  month         = jan,
  year          = "2007",
  pages         = "36--44",
  doi           = "10.1145/1188913.1188915",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  note          = "",
}

@Article{Cohen07,
  author        = "Sarah Cohen and Werner Nutt and Yehoshua Sagic",
  title         = "Deciding equivalances among conjunctive aggregate queries",
  journal       = JACM,
  articleno     = 5,
  numpages      = 50,
  volume        = 54,
  number        = 2,
  month         = apr,
  year          = 2007,
  doi           = "10.1145/1219092.1219093",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  acmid         = 1219093,
}


@periodical{JCohen96,
  key =          "Cohen",
  editor =       "Jacques Cohen",
  title =        "Special issue: Digital Libraries",
  journal =      CACM,
  volume =       "39",
  number =       "11",
  month =        nov,
  year =         "1996",
}


@Book{Kosiur01,
  author =       "David Kosiur",
  title =        "Understanding Policy-Based Networking",
  publisher =    "Wiley",
  year =         "2001",
  address =      "New York, NY",
  edition =      "2nd.",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Harel79,
  author =       "David Harel",
  year =         "1979",
  title =        "First-Order Dynamic Logic",
  series =       "Lecture Notes in Computer Science",
  volume =       "68",
  address =      "New York, NY",
  publisher =    "Springer-Verlag",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09237-4",
  editor =       "",
  number =       "",
  month =        "",
  note =         "",
}


@Inbook{Editor00,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book one",
  subtitle =     "The book subtitle",
  series =       "The name of the series one",
  year =         "2007",
  volume =       "9",
  address =      "Chicago",
  edition =      "1st.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  chapter =      "",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}

%
@InBook{Editor00a,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book two",
  subtitle =     "The book subtitle",
  series =       "The name of the series two",
  year =         "2008",
  address =      "Chicago",
  edition =      "2nd.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  volume =       "",
  chapter =      "100",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Spector90,
  author =       "Asad Z. Spector",
  title =        "Achieving application requirements",
  booktitle =    "Distributed Systems",
  publisher =    "ACM Press",
  address =      "New York, NY",
  year =         "1990",
  edition =      "2nd.",
  chapter =      "",
  editor =       "Sape Mullender",
  pages =        "19--33",
  doi =          "10.1145/90417.90738",
  url =          "http://doi.acm.org/10.1145/90417.90738",
  volume =       "",
  number =       "",
  series =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Douglass98,
  author =       "Bruce P. Douglass and David Harel and Mark B. Trakhtenbrot",
  title =        "Statecarts in use: structured analysis and object-orientation",
  series =       "Lecture Notes in Computer Science",
  booktitle =    "Lectures on Embedded Systems",
  publisher =    "Springer-Verlag",
  address =      "London",
  volume =       "1494",
  year =         "1998",
  chapter =      "",
  editor =       "Grzegorz Rozenberg and Frits W. Vaandrager",
  pages =        "368--394",
  doi =          "10.1007/3-540-65193-4_29",
  url =          "http://dx.doi.org/10.1007/3-540-65193-4_29",
  edition =      "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


@Book{Knuth97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.)",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  year =         "1997",
  address =      "",
  edition =      "",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Knuth98,
  author =       "Donald E. Knuth",
  year =         "1998",
  title =        "The Art of Computer Programming",
  series =       "Fundamental Algorithms",
  volume =       "1",
  edition =      "3rd",
  address =      "",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  doi =          "",
  url =          "",
  editor =       "",
  number =       "",
  month =        "",
  note =         "(book)",
}

%Inbook{Knuth97,
%  author =       "Donald E. Knuth",
%  title =        "The Art of Computer Programming",
%  booktitle =    "the booktitle",
%  edition =      "3",
%  volume =       "1",
%  year =         "1997",
%  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
%  editor =       "",
%  number =       "",
%  series =       "Fundamental Algorithms",
%  type =         "",
%  chapter =      "",
%  pages =        "",
%  address =      "",
%  month =        "",
%  note =         "(inbook)",
%}

%INBOOK{DK:73-inbook-full,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (inbook w series)",
%   volume = 1,
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   edition = "Second",
%   month = "10~" # jan,
%   year = "1973",
%   type = "Section",
%   chapter = "1.2",
%   pages = "10--119",
%   note = "Full INBOOK entry (w series)",
%}

%INcollection{DK:74-incoll,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1974",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor",
%}

%INcollection{DK:75-incollws,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll w series)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1975",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor and series",
%}


@incollection{GM05,
Author= "Dan Geiger and Christopher Meek",
Title= "Structured Variational Inference Procedures and their Realizations (as incol)",
Year= 2005,
Booktitle="Proceedings of Tenth International Workshop on Artificial Intelligence and Statistics, {\rm The Barbados}",
Publisher="The Society for Artificial Intelligence and Statistics",
Month= jan,
Editors= "Z. Ghahramani and R. Cowell"
}

@Inproceedings{Smith10,
  author =       "Stan W. Smith",
  title =        "An experiment in bibliographic mark-up: Parsing metadata for XML export",
  booktitle =    "Proceedings of the 3rd. annual workshop on Librarians and Computers",
  series =       "LAC '10",
  editor =       "Reginald N. Smythe and Alexander Noble",
  volume =       "3",
  year =         "2010",
  publisher =    "Paparazzi Press",
  address =      "Milan Italy",
  pages =        "422--431",
  doi =          "99.9999/woot07-S422",
  url =          "http://dx.doi.org/99.0000/woot07-S422",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy07,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2007,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '07",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    {Paper 7},
  numpages =     9,
}

@Inproceedings{VanGundy08,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2008,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '08",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    7,
  numpages =     2,
  pages =        "99-100",
}

@Inproceedings{VanGundy09,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         2009,
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '09",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  pages =        "90--100",
}

@Inproceedings{Andler79,
  author =       "Sten Andler",
  title =        "Predicate Path expressions",
  booktitle =    "Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages",
  series =       "POPL '79",
  year =         "1979",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "226--236",
  doi =          "10.1145/567752.567774",
  url =          "http://doi.acm.org/10.1145/567752.567774",
  editor =       "",
  volume =       "",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Techreport{Harel78,
  author =       "David Harel",
  year =         "1978",
  title =        "LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         "",
}

@MASTERSTHESIS{anisi03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}


@Phdthesis{Clarkson85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        "",
}


@online{Thornburg01,
  author =       "Harry Thornburg",
  year =         "2001",
  title =        "Introduction to Bayesian Statistics",
  url =          "http://ccrma.stanford.edu/~jos/bayes/bayes.html",
  month =        mar,
  lastaccessed = "March 2, 2005",
}


@online{Ablamowicz07,
  author =       "Rafal Ablamowicz and Bertfried Fauser",
  year =         "2007",
  title =        "CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11",
  url =          "http://math.tntech.edu/rafal/cliff11/index.html",
  lastaccessed = "February 28, 2008",
}


@misc{Poker06,
  author =       "Poker-Edge.Com",
  year =         "2006",
  month =        mar,
  title =        "Stats and Analysis",
  lastaccessed = "June 7, 2006",
  url =          "http://www.poker-edge.com/stats.php",
}

@misc{Obama08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A more perfect union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  "",
}

@misc{JoeScientist001,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = "",
}


@Inproceedings{Novak03,
  author =       "Dave Novak",
  title =        "Solder man",
  booktitle =    "ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27--27, 2003)",
  year =         "2003",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "4",
  month =        "March 21, 2008",
  doi =          "99.9999/woot07-S422",
  url =          "http://video.google.com/videoplay?docid=6528042696351994555",
  note =         "",
  howpublished = "Video",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  organization = "",
  distinctURL = 1
}


@article{Lee05,
  author =       "Newton Lee",
  year =         "2005",
  title =        "Interview with Bill Kinder: January 13, 2005",
  journal =      "Comput. Entertain.",
  eid =          "4",
  volume =       "3",
  number =       "1",
  month =        "Jan.-March",
  doi =          "10.1145/1057270.1057278",
  url =          "http://doi.acm.org/10.1145/1057270.1057278",
  howpublished = "Video",
  note =         "",
}

@article{rous08,
  author =       "Bernard Rous",
  year =         "2008",
  title =        "The Enabling of Digital Libraries",
  journal =      "Digital Libraries",
  volume =       "12",
  number =       "3",
  month =        jul,
  articleno =    "Article~5",
  doi =          "",
  url =          "",
  howpublished = "",
  note =         "To appear",
}

@article{384253,
 author = {Werneck,, Renato and Setubal,, Jo\~{a}o and da Conceic\~{a}o,, Arlindo},
 title = {(old) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 year = {2000},
 issn = {1084-6654},
 pages = {11},
 doi = {http://doi.acm.org/10.1145/351827.384253},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@article{Werneck:2000:FMC:351827.384253,
 author = {Werneck, Renato and Setubal, Jo\~{a}o and da Conceic\~{a}o, Arlindo},
 title = {(new) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = 5,
 month = dec,
 year = 2000,
 issn = {1084-6654},
 articleno = 11,
 url = {http://portal.acm.org/citation.cfm?id=351827.384253},
 doi = {10.1145/351827.384253},
 acmid = 384253,
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(old) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 doi = {http://dx.doi.org/10.1016/j.inffus.2009.01.002},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Conti:2009:DDS:1555009.1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(new) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 month = oct,
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 numpages = {12},
 url = {http://portal.acm.org/citation.cfm?id=1555009.1555162},
 doi = {10.1016/j.inffus.2009.01.002},
 acmid = {1555162},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Clone detection, Distributed protocol, Securing data fusion, Wireless sensor networks},
}

@inproceedings{Li:2008:PUC:1358628.1358946,
 author = {Li, Cheng-Lun and Buyuktur, Ayse G. and Hutchful, David K. and Sant, Natasha B. and Nainwal, Satyendra K.},
 title = {Portalis: using competitive online interactions to support aid initiatives for the homeless},
 booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 pages = {3873--3878},
 numpages = {6},
 url = {http://portal.acm.org/citation.cfm?id=1358628.1358946},
 doi = {10.1145/1358628.1358946},
 acmid = {1358946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cscw, distributed knowledge acquisition, incentive design, online games, recommender systems, reputation systems, user studies, virtual community},
}

@book{Hollis:1999:VBD:519964,
 author = {Hollis, Billy S.},
 title = {Visual Basic 6: Design, Specification, and Objects with Other},
 year = {1999},
 isbn = {0130850845},
 edition = {1st},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
 }


@book{Goossens:1999:LWC:553897,
 author = {Goossens, Michel and Rahtz, S. P. and Moore, Ross and Sutor, Robert S.},
 title = {The  Latex Web Companion: Integrating TEX, HTML, and XML},
 year = {1999},
 isbn = {0201433117},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

% need to test genres for errant isbn output

% techreport
@techreport{897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

@techreport{Buss:1987:VTB:897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

% whole proceedings

@proceedings{Czerwinski:2008:1358628,
 author = {},
 note = {General Chair-Czerwinski, Mary and General Chair-Lund, Arnie and Program Chair-Tan, Desney},
 title = {CHI '08: CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 order_no = {608085},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

% phdthesis

@phdthesis{Clarkson:1985:ACP:911891,
 author = {Clarkson, Kenneth Lee},
 advisor = {Yao, Andrew C.},
 title = {Algorithms for Closest-Point Problems (Computational Geometry)},
 year = {1985},
 note = {AAT 8506171},
 school = {Stanford University},
 address = {Stanford, CA, USA},
 }
% school is being picked up -- but not publisher (which is OK)
% Also -- the title is NOT being output in italics !!! Arrrrgh! - I fixed it. :-)


%%% compare with 'old'
%%% atsign-Phdthesis{Clarkson85,
%%%  author =       "Kenneth L. Clarkson",
%%%  year =         "1985",
%%%  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
%%%  school =       "Stanford University",
%%%  address =      "Palo Alto, CA",
%%%  note =         "UMI Order Number: AAT 8506171",
%%%  type =         "",
%%%  month =        "",
%%%}

% A bibliography
@Article{1984:1040142,
 key = {{$\!\!$}},
 journal = {SIGCOMM Comput. Commun. Rev.},
 year = {1984},
 issn = {0146-4833},
 volume = {13-14},
 number = {5-1},
 issue_date = {January/April 1984},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


% grinder
@inproceedings{2004:ITE:1009386.1010128,
 key = {IEEE},
 title = {IEEE TCSC Executive Committee},
 booktitle = {Proceedings of the IEEE International Conference on Web Services},
 series = {ICWS '04},
 year = {2004},
 isbn = {0-7695-2167-3},
 pages = {21--22},
 url = {http://dx.doi.org/10.1109/ICWS.2004.64},
 doi = {http://dx.doi.org/10.1109/ICWS.2004.64},
 acmid = {1010128},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

% div book
@book{Mullender:1993:DS:302430,
 editor = {Mullender, Sape},
 title = {Distributed systems (2nd Ed.)},
 year = {1993},
 isbn = {0-201-62427-3},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 address = {New York, NY, USA},
 }

% master thesis (as techreport and thesis)

@techreport{Petrie:1986:NAD:899644,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 publisher = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }

@MASTERSTHESIS{Petrie:1986:NAD:12345,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 school = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }




@BOOK{book-minimal,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   publisher = "Addison-Wesley",
   year = "1981",
}

% incollection (has an editor, title, and possibly a booktitle)
@INcollection{KA:2001,
 author = {Kong, Wei-Chang},
 Title = {The implementation of electronic commerce in SMEs in Singapore (as Incoll)},
 booktitle = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}


% with bibfield 'type' before chapter (note no editor)
@INBOOK{KAGM:2001,
 author = {Kong, Wei-Chang},
 type = {Name of Chapter:},
 chapter = {The implementation of electronic commerce in SMEs in Singapore (Inbook-w-chap-w-type)},
 title = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

%%% Notes! This is because the atsign-INBOOK citation type specifies EITHER
%%% editor or author, but not both. In my experiments with the harvard/dcu
%%% bibtex style (and presumably this applies to other styles too), bibtex
%%% ignores the editor information if author information exists in an
%%% atsign-INBOOK entry. atsign-INCOLLECTION is far more commonly used in my references,
%%% and in the absence of an editor I believe most bibtex styles will just
%%% ommit the editor from the reference - the chapter information will not
%%% end up in the in-text citation as you suggest it should be but at least
%%% there is a place to put the editor if necessary.


@article{Brundage2020e,
abstract = {With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.},
archivePrefix = {arXiv},
arxivId = {2004.07213},
author = {Brundage, Miles and Avin, Shahar and Wang, Jasmine and Belfield, Haydn and Krueger, Gretchen and Hadfield, Gillian and Khlaaf, Heidy and Yang, Jingying and Toner, Helen and Fong, Ruth and Maharaj, Tegan and Koh, Pang Wei and Hooker, Sara and Leung, Jade and Trask, Andrew and Bluemke, Emma and Lebensold, Jonathan and O'Keefe, Cullen and Koren, Mark and Ryffel, Th{\'{e}}o and Rubinovitz, JB and Besiroglu, Tamay and Carugati, Federica and Clark, Jack and Eckersley, Peter and de Haas, Sarah and Johnson, Maritza and Laurie, Ben and Ingerman, Alex and Krawczuk, Igor and Askell, Amanda and Cammarota, Rosario and Lohn, Andrew and Krueger, David and Stix, Charlotte and Henderson, Peter and Graham, Logan and Prunkl, Carina and Martin, Bianca and Seger, Elizabeth and Zilberman, Noa and H{\'{E}}igeartaigh, Se{\'{a}}n {\'{O}} and Kroeger, Frens and Sastry, Girish and Kagan, Rebecca and Weller, Adrian and Tse, Brian and Barnes, Elizabeth and Dafoe, Allan and Scharre, Paul and Herbert-Voss, Ariel and Rasser, Martijn and Sodhani, Shagun and Flynn, Carrick and Gilbert, Thomas Krendl and Dyer, Lisa and Khan, Saif and Bengio, Yoshua and Anderljung, Markus},
eprint = {2004.07213},
file = {:C$\backslash$:/Users/shala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brundage et al. - 2020 - Toward Trustworthy AI Development Mechanisms for Supporting Verifiable Claims.pdf:pdf},
mendeley-groups = {PhD/AI competency project},
title = {{Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims}},
url = {http://arxiv.org/abs/2004.07213},
year = {2020}
}
@inproceedings{Holstein2019,
abstract = {The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs.},
archivePrefix = {arXiv},
arxivId = {1812.05239},
author = {Holstein, Kenneth and Vaughan, Jennifer Wortman and Daum{\'{e}}, Hal and Dud{\'{i}}k, Miroslav and Wallach, Hanna},
booktitle = {Conf. Hum. Factors Comput. Syst. - Proc.},
doi = {10.1145/3290605.3300830},
eprint = {1812.05239},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/improving fairness in ML systems - what do industry practitioners need.pdf:pdf},
isbn = {9781450359702},
keywords = {Algorithmic bias,Empirical study,Fair machine learning,Need-finding,Product teams,UX of machine learning},
mendeley-groups = {PhD/AI competency project},
title = {{Improving fairness in machine learning systems: What do industry practitioners need?}},
year = {2019}
}
@inproceedings{Belfield2020,
abstract = {The artificial intelligence (AI) community has recently engaged in activism in relation to their employers, other members of the community, and their governments in order to shape the societal and ethical implications of AI. It has achieved some notable successes, but prospects for further political organising and activism are uncertain. We survey activism by the AI community over the last six years; apply two analytical frameworks drawing upon the literature on epistemic communities, and worker organising and bargaining; and explore what they imply for the future prospects of the AI community. Success thus far has hinged on a coherent shared culture, and high bargaining power due to the high demand for a limited supply of AI 'talent'. Both are crucial to the future of AI activism and worthy of sustained attention.},
author = {Belfield, Haydn},
booktitle = {AIES 2019 - Proc. 2019 AAAI/ACM Conf. AI, Ethics, Soc.},
doi = {10.1145/3375627.3375814},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/activitist by AI ethics community.pdf:pdf},
isbn = {9781450371100},
mendeley-groups = {PhD/AI competency project},
pages = {15--21},
title = {{Activism by the AI Community}},
year = {2020}
}
@techreport{Bruneault2022,
author = {Bruneault, Fr{\'{e}}d{\'{e}}rick and Andr{\'{e}}-laurendeau, C{\'{e}}gep and Laflamme, Andr{\'{e}}ane Sabourin and Fillion, Gabrielle and Abtroun, Neila and Freeman, Andrew},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/22949-Cegep-Andre-Laurendeau-Referentiel-de-competence-V4-FINAL-Interactif (1).pdf:pdf},
mendeley-groups = {PhD/AI competency project},
number = {February},
title = {{AI Ethics Training in Higher Education : Competency Framework}},
year = {2022}
}
@techreport{YuriDemchenkoAdamBelloum2017,
author = {{Yuri Demchenko, Adam Belloum}, Tomasz Wiktorski},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/edison{\_}cf-ds-release2-v08{\_}0.pdf:pdf},
mendeley-groups = {PhD/AI competency project},
number = {July},
pages = {1--59},
title = {{EDISON Data Science Framework: Part1. Data Science Competence Framework Release 2}},
url = {https://edison-project.eu/sites/edison-project.eu/files/filefield{\_}paths/edison{\_}cf-ds-release2-v08{\_}0.pdf},
year = {2017}
}
@techreport{Blok2021,
author = {Blok, Sherry and Trudeau, Joel and Cassidy, Robert},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Corrected-FINAL{\_}PIA{\_}ConcordiaDawson{\_}AICompetencyFramework.pdf:pdf},
mendeley-groups = {PhD/AI competency project},
number = {September},
title = {{Artificial Intelligence Competency Framework Table of Contents}},
year = {2021}
}
@article{Rakova2021c,
abstract = {Large and ever-evolving technology companies continue to invest more time and resources to incorporate responsible Artificial Intelligence (AI) into production-ready systems to increase algorithmic accountability. This paper examines and seeks to offer a framework for analyzing how organizational culture and structure impact the effectiveness of responsible AI initiatives in practice. We present the results of semi-structured qualitative interviews with practitioners working in industry, investigating common challenges, ethical tensions, and effective enablers for responsible AI initiatives. Focusing on major companies developing or utilizing AI, we have mapped what organizational structures currently support or hinder responsible AI initiatives, what aspirational future processes and structures would best enable effective initiatives, and what key elements comprise the transition from current work practices to the aspirational future.},
archivePrefix = {arXiv},
arxivId = {2006.12358},
author = {Rakova, Bogdana and Yang, Jingying and Cramer, Henriette and Chowdhury, Rumman},
doi = {10.1145/3449081},
eprint = {2006.12358},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Where Responsible AI meets Reality - Practitioner's Perspective.pdf:pdf},
issn = {25730142},
journal = {Proc. ACM Human-Computer Interact.},
keywords = {industry practice,organizational structure,responsible ai},
mendeley-groups = {PhD/AI competency project},
number = {CSCW1},
pages = {1--23},
title = {{Where Responsible AI meets Reality: Practitioner Perspectives on Enablers for Shifting Organizational Practices}},
volume = {5},
year = {2021}
}
@article{Gambelin2021,
abstract = {Despite there being a strong call for responsible technology, the path towards putting ethics into action is still yet to be fully understood. To help guide the implementation of ethics, we have seen the rise of a new professional title; the AI Ethicist. However, it is still unclear what the role and skill set of this new profession must include. The purpose of this piece is to offer a preliminary definition of what it means to be an AI Ethicist by first examining the concept of an ethicist in the context of artificial intelligence, followed by exploring what responsibilities are added to the role in industry specifically, and ending on the fundamental characteristic that underlies it all: bravery.},
author = {Gambelin, Olivia},
doi = {10.1007/s43681-020-00020-5},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Gambelin2020{\_}Article{\_}BraveWhatItMeansToBeAnAIEthici.pdf:pdf},
isbn = {0123456789},
issn = {2730-5953},
journal = {AI Ethics},
keywords = {AI Ethics,Artificial intelligence,Bravery,Ethical decision making,ai ethics,artificial intelligence,bravery,ethical decision making},
mendeley-groups = {PhD/AI competency project},
number = {1},
pages = {87--91},
publisher = {Springer International Publishing},
title = {{Brave: what it means to be an AI Ethicist}},
url = {https://doi.org/10.1007/s43681-020-00020-5},
volume = {1},
year = {2020}
}
@inproceedings{Raji2021,
abstract = {Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS) - -and its implications for AI - -has led to the current "ethics crisis". However, we claim that the current AI ethics education space relies on a form of "exclusionary pedagogy,"where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as "ethical unicorns"that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.},
author = {Raji, Inioluwa Deborah and Scheuerman, Morgan Klaus and Amironesei, Razvan},
booktitle = {FAccT 2021 - Proc. 2021 ACM Conf. Fairness, Accountability, Transpar.},
doi = {10.1145/3442188.3445914},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Raji-pedagogy2021.pdf:pdf},
isbn = {9781450383097},
mendeley-groups = {PhD/AI competency project},
pages = {515--525},
title = {{"you can't sit with us": Exclusionary pedagogy in AI ethics education}},
year = {2021}
}

@MISC{orcaa,
  title        = "ORCAA",
  author       = "ORCAA Consulting", 
  year         = "2023",
  howpublished = "\url{https://orcaarisk.com/}",
  note         = "Accessed: 2023-3-15",
  language     = "en"
}

@MISC{Lab2019-ur,
  title        = "AI Ethics Lab",
  author       = "AI Ethics Lab",
  month        =  dec,
  year         =  2019,
  howpublished = "\url{https://aiethicslab.com/}",
  note         = "Accessed: 2023-3-15",
  language     = "en"
}

@MISC{ethical-advisory,
  title        = "Ethical AI Advisory",
  author       = "Ethical AI Advisory",
  year         = 2023, 
  howpublished = "\url{https://www.ethicalai.ai/}",
  note         = "Accessed: 2023-3-15",
  language     = "en"
}



@article{Fjeld2020-rb,
  title    = "Principled Artificial Intelligence: Mapping Consensus in Ethical
              and Rights-Based Approaches to Principles for AI",
  author   = "Fjeld, Jessica and Achten, Nele and Hilligoss, Hannah and Nagy,
              Adam and Srikumar, Madhulika",
  abstract = "The rapid spread of artificial intelligence (AI) systems has
              precipitated a rise in ethical and human rights-based frameworks
              intended to guide the development and use of these technologies.
              Despite the proliferation of these ``AI principles,'' there has
              been little scholarly focus on understanding these efforts either
              individually or as contextualized within an expanding universe of
              principles with discernible trends.To that end, this white paper
              and its associated data visualization compare the contents of
              thirty-six prominent AI principles documents side-by-side. This
              effort uncovered a growing consensus around eight key thematic
              trends: privacy, accountability, safety and security,
              transparency and explainability, fairness and non-discrimination,
              human control of technology, professional responsibility, and
              promotion of human values. Underlying this ``normative core,''
              our analysis examined the forty-seven individual principles that
              make up the themes, detailing notable similarities and
              differences in interpretation found across the documents. In
              sharing these observations, it is our hope that policymakers,
              advocates, scholars, and others working to maximize the benefits
              and minimize the harms of AI will be better positioned to build
              on existing efforts and to push the fractured, global
              conversation on the future of AI toward consensus.",
  month    =  jan,
  year     =  2020
}

@ARTICLE{Jobin2019-kt,
  title     = "The global landscape of AI ethics guidelines",
  author    = "Jobin, Anna and Ienca, Marcello and Vayena, Effy",
  abstract  = "In the past five years, private companies, research institutions
               and public sector organizations have issued principles and
               guidelines for ethical artificial intelligence (AI). However,
               despite an apparent agreement that AI should be `ethical', there
               is debate about both what constitutes `ethical AI' and which
               ethical requirements, technical standards and best practices are
               needed for its realization. To investigate whether a global
               agreement on these questions is emerging, we mapped and analysed
               the current corpus of principles and guidelines on ethical AI.
               Our results reveal a global convergence emerging around five
               ethical principles (transparency, justice and fairness,
               non-maleficence, responsibility and privacy), with substantive
               divergence in relation to how these principles are interpreted,
               why they are deemed important, what issue, domain or actors they
               pertain to, and how they should be implemented. Our findings
               highlight the importance of integrating guideline-development
               efforts with substantive ethical analysis and adequate
               implementation strategies. As AI technology develops rapidly, it
               is widely recognized that ethical guidelines are required for
               safe and fair implementation in society. But is it possible to
               agree on what is `ethical AI'? A detailed analysis of 84 AI
               ethics reports around the world, from national and international
               organizations, companies and institutes, explores this question,
               finding a convergence around core principles but substantial
               divergence on practical implementation.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  9,
  pages     = "389--399",
  month     =  sep,
  year      =  2019,
  language  = "en"
}


@INPROCEEDINGS{Rismani2023-im,
  title           = "From Plane Crashes to Algorithmic Harm: Applicability of
                     Safety Engineering Frameworks for Responsible {ML}",
  booktitle       = "Proceedings of the 2023 {CHI} Conference on Human Factors
                     in Computing Systems ({CHI} '23)",
  author          = "Rismani, Shalaleh and Shelby, Renee and Smart, Andrew and
                     Jatho, Edgar and Kroll, Josh A and Moon, Ajung and
                     Rostamzadeh, Negar",
  publisher       = "Association for Computing Machinery",
  volume          =  1,
  month           =  apr,
  year            =  2023,
  location        = " Hamburg, Germany"
}

@ARTICLE{Shelby2022-oi,
  title         = "Identifying Sociotechnical Harms of Algorithmic Systems:
                   Scoping a Taxonomy for Harm Reduction",
  author        = "Shelby, Renee and Rismani, Shalaleh and Henne, Kathryn and
                   Moon, Ajung and Rostamzadeh, Negar and Nicholas, Paul and
                   Yilla, N'mah and Gallegos, Jess and Smart, Andrew and
                   Garcia, Emilio and Virk, Gurleen",
  abstract      = "Understanding the landscape of potential harms from
                   algorithmic systems enables practitioners to better
                   anticipate consequences of the systems they build. It also
                   supports the prospect of incorporating controls to help
                   minimize harms that emerge from the interplay of
                   technologies and social and cultural dynamics. A growing
                   body of scholarship has identified a wide range of harms
                   across different algorithmic technologies. However,
                   computing research and practitioners lack a high level and
                   synthesized overview of harms from algorithmic systems
                   arising at the micro, meso-, and macro-levels of society. We
                   present an applied taxonomy of sociotechnical harms to
                   support more systematic surfacing of potential harms in
                   algorithmic systems. Based on a scoping review of computing
                   research $(n=172)$, we identified five major themes related
                   to sociotechnical harms - representational, allocative,
                   quality-of-service, interpersonal harms, and social
                   system/societal harms - and sub-themes. We describe these
                   categories and conclude with a discussion of challenges and
                   opportunities for future research.",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC",
  eprint        = "2210.05791"
}


@INPROCEEDINGS{Weidinger2022-ni,
  title     = "Taxonomy of Risks posed by Language Models",
  booktitle = "2022 {ACM} Conference on Fairness, Accountability, and
               Transparency",
  author    = "Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and
               Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese,
               Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa
               and Biles, Courtney and Brown, Sasha and Kenton, Zac and
               Hawkins, Will and Stepleton, Tom and Birhane, Abeba and
               Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and
               Haas, Julia and Legassick, Sean and Irving, Geoffrey and
               Gabriel, Iason",
  abstract  = "Responsible innovation on large-scale Language Models (LMs)
               requires foresight into and in-depth understanding of the risks
               these models may pose. This paper develops a comprehensive
               taxonomy of ethical and social risks associated with LMs. We
               identify twenty-one risks, drawing on expertise and literature
               from computer science, linguistics, and the social sciences. We
               situate these risks in our taxonomy of six risk areas: I.
               Discrimination, Hate speech and Exclusion, II. Information
               Hazards, III. Misinformation Harms, IV. Malicious Uses, V.
               Human-Computer Interaction Harms, and VI. Environmental and
               Socioeconomic harms. For risks that have already been observed
               in LMs, the causal mechanism leading to harm, evidence of the
               risk, and approaches to risk mitigation are discussed. We
               further describe and analyse risks that have not yet been
               observed but are anticipated based on assessments of other
               language technologies, and situate these in the same taxonomy.
               We underscore that it is the responsibility of organizations to
               engage with the mitigations we discuss throughout the paper. We
               close by highlighting challenges and directions for further
               research on risk evaluation and mitigation with the goal of
               ensuring that language models are developed responsibly.",
  publisher = "Association for Computing Machinery",
  pages     = "214--229",
  series    = "FAccT '22",
  month     =  jun,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "responsible AI, language models, risk assessment, responsible
               innovation, technology risks",
  location  = "Seoul, Republic of Korea"
}

@ARTICLE{Stuurman2022-kb,
  title    = "Regulating {AI}. A label to complete the proposed Act on
              Artificial Intelligence",
  author   = "Stuurman, Kees and Lachaud, Eric",
  abstract = "AI regulation is emerging in the EU. The European authorities,
              NGOs and academics have already issued a series of proposals to
              accommodate the `development and uptake of AI' with an
              `appropriate ethical and legal framework' and promote what the
              European Commission has called an `ecosystem of trust'. In the
              spring of 2020, the European Commission submitted a legislative
              proposal for public consultation including four options ranging
              from ``soft law only'' to a broad scope of mandatory requirements
              and combinations thereof, for addressing the risks linked to the
              development and use of certain AI applications. One year later,
              the Commission unveiled on 21 April 2021 the EU Act on Artificial
              Intelligence.11Regulation of the European Parliament and of the
              Council laying down harmonised rules on artificial intelligence
              (artificial intelligence act) and amending certain union
              legislative acts, Brussels, 21.4.2021 COM (2021) 206 final. The
              proposal primarily focusses on regulating 'high-risk' systems
              through mandatory requirements and prohibition measures. This
              approach leaves a wide range of AI-systems, with potentially
              serious impact on fundamental rights, merely unregulated as
              regards specifically AI related risks. This paper explores the
              boundaries of the impact of the Act for primarily non-high-risk
              systems and discuss the options for introducing a voluntary
              labelling scheme for enhancing protection against the risks of
              medium and low risk AI systems.",
  journal  = "Computer Law \& Security Review",
  volume   =  44,
  pages    = "105657",
  month    =  apr,
  year     =  2022,
  keywords = "AI regulation; Labels; Certification; Self-regulation; Soft law"
}

@MISC{aida-euai,
  title        = "The Regulation of Artificial Intelligence in Canada and
                  Abroad: Comparing the Proposed {AIDA} and {EU} {AI} Act",
  publisher    = "Fasken",
  month        =  oct,
  year         =  2022,
  howpublished = "\url{https://www.fasken.com/en/knowledge/2022/10/18-the-regulation-of-artificial-intelligence-in-canada-and-abroad}",
  note         = "Accessed: 2023-2-15",
  language     = "en"
}

@ARTICLE{Heikkila2022-ld,
  title    = "Responsible {AI} has a burnout problem",
  author   = "Heikkil{\"a}, Melissa",
  abstract = "Companies say they want ethical AI. But those working in the
              field say that ambition comes at their expense.",
  journal  = "MIT Technology Review",
  month    =  oct,
  year     =  2022,
  language = "en"
}

@ARTICLE{Farr2009-ab,
  title     = "Leadership Skills Development for Engineers",
  author    = "Farr, John V and Brazil, Donna M",
  abstract  = "Abstract:Leadership must be a key element advancing for the
               engineering profession to remain relevant and connected in an
               era of heightened outsourcing and global competition. Companies
               intent on maintaining a competitive edge are calling upon
               educators to produce engineers capable of leading
               multidisciplinary teams, combine technical ingenuity with
               business acumen, and produce graduates who have a passion for
               lifelong learning. Industry is also challenging universities to
               broaden curricula beyond the intellectual endeavors of design
               and scientific inquiry to the greater domain of professional
               leadership and entrepreneurship. Managers in industry are
               similarly challenged to cultivate key leadership attributes in
               junior engineers. This article explores the changing nature of
               engineering in a globally competitive environment and addresses
               why leadership must become a key issue in the career progression
               of engineers. We will present a literature review of leadership
               models along with some proposed solutions for cultivating
               leadership skills as part of the career development process.
               Lastly, we will present specific recommendations on how to
               cultivate leadership attributes throughout an engineering
               career.",
  journal   = "Engineering Management Journal",
  publisher = "Taylor \& Francis",
  volume    =  21,
  number    =  1,
  pages     = "3--8",
  month     =  mar,
  year      =  2009
}

@ARTICLE{Farr2009-ab,
  title     = "Leadership Skills Development for Engineers",
  author    = "Farr, John V and Brazil, Donna M",
  abstract  = "Abstract:Leadership must be a key element advancing for the
               engineering profession to remain relevant and connected in an
               era of heightened outsourcing and global competition. Companies
               intent on maintaining a competitive edge are calling upon
               educators to produce engineers capable of leading
               multidisciplinary teams, combine technical ingenuity with
               business acumen, and produce graduates who have a passion for
               lifelong learning. Industry is also challenging universities to
               broaden curricula beyond the intellectual endeavors of design
               and scientific inquiry to the greater domain of professional
               leadership and entrepreneurship. Managers in industry are
               similarly challenged to cultivate key leadership attributes in
               junior engineers. This article explores the changing nature of
               engineering in a globally competitive environment and addresses
               why leadership must become a key issue in the career progression
               of engineers. We will present a literature review of leadership
               models along with some proposed solutions for cultivating
               leadership skills as part of the career development process.
               Lastly, we will present specific recommendations on how to
               cultivate leadership attributes throughout an engineering
               career.",
  journal   = "Engineering Management Journal",
  publisher = "Taylor \& Francis",
  volume    =  21,
  number    =  1,
  pages     = "3--8",
  month     =  mar,
  year      =  2009
}

@ARTICLE{Knight2022-ym,
  title    = "Elon Musk Has Fired Twitter's `Ethical {AI'} Team",
  author   = "Knight, Will",
  abstract = "As part of a wave of layoffs, the new CEO disbanded a group
              working to make Twitter's algorithms more transparent and fair.",
  journal  = "Wired",
  month    =  nov,
  year     =  2022,
  language = "en"
}

@INPROCEEDINGS{Bessen2022-gy,
  title     = "The Cost of Ethical {AI} Development for {AI} Startups",
  booktitle = "Proceedings of the 2022 {AAAI/ACM} Conference on {AI}, Ethics,
               and Society",
  author    = "Bessen, James and Impink, Stephen Michael and Seamans, Robert",
  abstract  = "Artificial Intelligence startups use training data as direct
               inputs in product development. These firms must balance numerous
               tradeoffs between ethical issues and data access without
               substantive guidance from regulators or existing judicial
               precedence. We survey these startups to determine what actions
               they have taken to address these ethical issues and the
               consequences of those actions. We find that 58\% of these
               startups have established a set of AI principles. Startups with
               data-sharing relationships with high-technology firms or that
               have prior experience with privacy regulations are more likely
               to establish ethical AI principles and are more likely to take
               costly steps, like dropping training data or turning down
               business, to adhere to their ethical AI policies. Moreover,
               startups with ethical AI policies are more likely to invest in
               unconscious bias training, hire ethnic minorities and female
               programmers, seek expert advice, and search for more diverse
               training data. Potential costs associated with data-sharing
               relationships and the adherence to ethical policies may create
               tradeoffs between increased AI product competition and more
               ethical AI production.",
  publisher = "Association for Computing Machinery",
  pages     = "92--106",
  series    = "AIES '22",
  month     =  jul,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "scale barriers, ethics, startups, data, AI",
  location  = "Oxford, United Kingdom"
}

@ARTICLE{mit_2021-dg,
  title    = "Embracing the rapid pace of {AI}",
  abstract = "Artificial intelligence is changing every industry---from
              manufacturing to retail. It's also changing the culture at
              companies as they strive to keep up with accelerating digital
              technologies.",
  journal  = "MIT Technology Review",
  month    =  may,
  year     =  2021,
  language = "en"
}

@INPROCEEDINGS{Meek2016-wz,
  title     = "Managing the ethical and risk implications of rapid advances in
               artificial intelligence: A literature review",
  booktitle = "2016 Portland International Conference on Management of
               Engineering and Technology ({PICMET})",
  author    = "Meek, Taylor and Barham, Husam and Beltaif, Nader and Kaadoor,
               Amani and Akhter, Tanzila",
  abstract  = "The development of emergent technologies carries with it ethical
               issues and risks. We review ways to better manage the ethical
               issues and risks of one emerging technology: Artificial
               Intelligence (AI). Depending on how AI's development is managed,
               it may have beneficial and/or deleterious effects. The
               processing capacity of Tianhe-2, the world's fastest
               supercomputer, by some measures, exceeds the processing capacity
               of a single human brain. but at a prohibitive processing/power
               consumption ratio and physical size. Given the current pace of
               AI R\&D activities, some estimates in the literature suggest
               that the technology could become capable of self-determination
               and super intelligence in only a few decades. This demands a
               serious analysis of the ethical implications of AI's development
               and the risks it might pose, in addition to technology
               management recommendations. We review the state of AI
               development, the timeline and scope of its possible future
               development, and potential ethical risks in its implementation.
               Further, we briefly review ethics and risk management practices
               as they relate to technology. Finally, we make technology
               management recommendations, which may help to address the
               ethical implications and to mitigate existential risks to
               humanity-with the development and dissemination of AI-by guiding
               its proper management.",
  publisher = "ieeexplore.ieee.org",
  pages     = "682--693",
  month     =  sep,
  year      =  2016,
  keywords  = "Artificial intelligence;Ethics;Technology
               management;Technological innovation;History;Computers;Process
               control"
}

@MISC{Goldman2022-ip,
  title        = "Why Meta and Twitter's {AI} and {ML} layoffs matter",
  author       = "Goldman, Sharon",
  month        =  nov,
  year         =  2022,
  howpublished = "\url{https://venturebeat.com/ai/why-meta-and-twitters-ai-and-ml-layoffs-matter-the-ai-beat/}",
  note         = "Accessed: 2023-3-12"
}

@INPROCEEDINGS{Carter2011-np,
  title     = "Ideas for adding soft skills education to service learning and
               capstone courses for computer science students",
  booktitle = "Proceedings of the 42nd {ACM} technical symposium on Computer
               science education",
  author    = "Carter, Lori",
  abstract  = "Soft skills such as communication, teamwork, and organization
               are important to students' future success in the working world.
               Faculty members know it, students know it, and employers are
               explicitly asking for these skills. Are computer science
               departments responsible to teach these skills? If so, where in
               the curriculum should they be covered? This paper explores the
               soft skills that employers want, and possible places to include
               the teaching of those skills in the curriculum. It then shows
               how an extensive set of soft skills were incorporated into a
               service learning course for the students in the Mathematical,
               Information and Computer Sciences department at Point Loma
               Nazarene University. Finally, it makes suggestions as to how
               other service learning or capstone courses could be altered to
               afford more opportunity for soft skill education.",
  publisher = "Association for Computing Machinery",
  pages     = "517--522",
  series    = "SIGCSE '11",
  month     =  mar,
  year      =  2011,
  address   = "New York, NY, USA",
  keywords  = "soft skills, service learning in computer science, communication",
  location  = "Dallas, TX, USA"
}

@ARTICLE{Hall2001-rg,
  title     = "Interdisciplinary education and teamwork: a long and winding
               road",
  author    = "Hall, P and Weaver, L",
  abstract  = "PURPOSE: This article examines literature on interdisciplinary
               education and teamwork in health care, to discover the major
               issues and best practices. METHODS: A literature review of
               mainly North American articles using search terms such as
               interdisciplinary, interprofessional, multidisciplinary with
               medical education. MAIN FINDINGS: Two issues are emerging in
               health care as clinicians face the complexities of current
               patient care: the need for specialized health professionals, and
               the need for these professionals to collaborate.
               Interdisciplinary health care teams with members from many
               professions answer the call by working together, collaborating
               and communicating closely to optimize patient care. Education on
               how to function within a team is essential if the endeavour is
               to succeed. Two main categories of issues emerged: those related
               to the medical education system and those related to the content
               of the education. CONCLUSIONS: Much of the literature pertained
               to programme evaluations of academic activities, and did not
               compare interdisciplinary education with traditional methods.
               Many questions about when to educate, who to educate and how to
               educate remain unanswered and open to future research.",
  journal   = "Med. Educ.",
  publisher = "Wiley Online Library",
  volume    =  35,
  number    =  9,
  pages     = "867--875",
  month     =  sep,
  year      =  2001,
  language  = "en"
}

@ARTICLE{Dyer2003-bd,
  title     = "Multidisciplinary, Interdisciplinary, and
               {TransdisciplinaryEducational} Models and Nursing Education",
  author    = "Dyer, Jean A",
  abstract  = "making an informed decision about integrated curriculum
               development and course implementation, multidisciplinary,
               interdisciplinary, and transdisciplinary educational teams are
               defined. Examples are offered that reflect these three
               integrated educational team models. Finally, the benefits and
               potential problem areas that result from team initiatives are
               briefly reviewed....",
  journal   = "Nurs. Educ. Perspect.",
  publisher = "journals.lww.com",
  volume    =  24,
  number    =  4,
  pages     = "186",
  year      =  2003
}

@ARTICLE{Klaassen2018-tk,
  title     = "Interdisciplinary education: a case study",
  author    = "Klaassen, Renate G",
  abstract  = "ABSTRACTToday, interdisciplinary education is a hot topic.
               Gaining an insight into the nature of interdisciplinary
               education may help when making design decisions for
               interdisciplinary education. In this study, we argue that,
               derived from interdisciplinary research, the choice of problem,
               the level of interaction between different disciplines and
               constructive alignment are variables to consider when designing
               interdisciplinary education. Several models of analysis have
               been used in two descriptive case studies to gain insight into
               the design parameters for interdisciplinary education. In this
               study, we AIM to describe (a) the level and nature of
               integration, (b) the problem definitions as a guiding principle
               for constructive alignment for (c) the design and execution of
               interdisciplinary/transdisciplinary education.",
  journal   = "Eur. J. Eng. Educ.",
  publisher = "Taylor \& Francis",
  volume    =  43,
  number    =  6,
  pages     = "842--859",
  month     =  nov,
  year      =  2018
}

@ARTICLE{Braun2006-rj,
  title     = "Using thematic analysis in psychology",
  author    = "Braun, Virginia and Clarke, Victoria",
  abstract  = "Thematic analysis is a poorly demarcated, rarely acknowledged,
               yet widely used qualitative analytic method within psychology.
               In this paper, we argue that it offers an accessible and
               theoretically flexible approach to analysing qualitative data.
               We outline what thematic analysis is, locating it in relation to
               other qualitative analytic methods that search for themes or
               patterns, and in relation to different epistemological and
               ontological positions. We then provide clear guidelines to those
               wanting to start thematic analysis, or conduct it in a more
               deliberate and rigorous way, and consider potential pitfalls in
               conducting thematic analysis. Finally, we outline the
               disadvantages and advantages of thematic analysis. We conclude
               by advocating thematic analysis as a useful and flexible method
               for qualitative research in and beyond psychology.",
  journal   = "Qual. Res. Psychol.",
  publisher = "Routledge",
  volume    =  3,
  number    =  2,
  pages     = "77--101",
  month     =  jan,
  year      =  2006
}

@ARTICLE{Mokander2022-ae,
  title    = "Conformity Assessments and Post-market Monitoring: A Guide to the
              Role of Auditing in the Proposed European {AI} Regulation",
  author   = "M{\"o}kander, Jakob and Axente, Maria and Casolari, Federico and
              Floridi, Luciano",
  abstract = "The proposed European Artificial Intelligence Act (AIA) is the
              first attempt to elaborate a general legal framework for AI
              carried out by any major global economy. As such, the AIA is
              likely to become a point of reference in the larger discourse on
              how AI systems can (and should) be regulated. In this article, we
              describe and discuss the two primary enforcement mechanisms
              proposed in the AIA: the conformity assessments that providers of
              high-risk AI systems are expected to conduct, and the post-market
              monitoring plans that providers must establish to document the
              performance of high-risk AI systems throughout their lifetimes.
              We argue that the AIA can be interpreted as a proposal to
              establish a Europe-wide ecosystem for conducting AI auditing,
              albeit in other words. Our analysis offers two main
              contributions. First, by describing the enforcement mechanisms
              included in the AIA in terminology borrowed from existing
              literature on AI auditing, we help providers of AI systems
              understand how they can prove adherence to the requirements set
              out in the AIA in practice. Second, by examining the AIA from an
              auditing perspective, we seek to provide transferable lessons
              from previous research about how to refine further the regulatory
              approach outlined in the AIA. We conclude by highlighting seven
              aspects of the AIA where amendments (or simply clarifications)
              would be helpful. These include, above all, the need to translate
              vague concepts into verifiable criteria and to strengthen the
              institutional safeguards concerning conformity assessments based
              on internal checks.",
  journal  = "Minds Mach.",
  volume   =  32,
  number   =  2,
  pages    = "241--268",
  year     =  2022,
  keywords = "Artificial Intelligence; Auditing; Conformity assessment;
              European Union; Governance; Regulation; Technology",
  language = "en"
}

@techreport{Moss2020,
author = {Moss, Emanuel and Metcalf, Jacob},
booktitle = {Data Soc.},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Ethics-Owners{\_}20200923-DataSociety.pdf:pdf},
mendeley-groups = {PhD/AI competency project},
pages = {1--71},
title = {{Ethics Owners: A new model of organizational responsibility in data-driven technology companies}},
year = {2020}
}
@inproceedings{Fiesler2020,
abstract = {As issues of technology ethics become more pervasive in the media and public discussions, there is increasing interest in what role ethics should play in computing education. Not only are there more standalone ethics classes being offered at universities, but calls for greater integration of ethics across computer science curriculum mean that a growing number of CS instructors may be including ethics as part of their courses. To both describe current trends in computing ethics coursework and to provide guidance for further ethics inclusion in computing, we present an in-depth qualitative analysis of 115 syllabi from university technology ethics courses. Our analysis contributes a snapshot of the content and goals of tech ethics classes, and recommendations for how these might be integrated across a computing curriculum. CCS CONCEPTS • Social and professional topics → Computing education.},
author = {Fiesler, Casey and Garrett, Natalie and Beard, Nathan},
booktitle = {SIGCSE '20},
doi = {10.1145/3328778.3366825},
file = {:C$\backslash$:/Users/shala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiesler, Garrett, Beard - 2020 - What Do We Teach When We Teach Tech Ethics A Syllabi Analysis.pdf:pdf},
isbn = {9781450367936},
keywords = {curriculum,ethics,professional responsibility,syllabi},
mendeley-groups = {PhD,PhD/AI competency project},
title = {{What Do We Teach When We Teach Tech Ethics? A Syllabi Analysis}},
url = {https://doi.org/10.1145/3328778.3366825},
year = {2020}
}
@article{Borenstein2021,
abstract = {Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people's lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.},
author = {Borenstein, Jason and Howard, Ayanna},
doi = {10.1007/s43681-020-00002-7},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/Borenstein-Howard2021{\_}Article{\_}EmergingChallengesInAIAndTheNe.pdf:pdf},
isbn = {0123456789},
issn = {2730-5953},
journal = {AI Ethics},
keywords = {AI ethics,Artificial intelligence,Design ethics,Ethics education,Professional responsibility,ai ethics,artificial intelligence,design ethics,ethics education,professional responsibility},
mendeley-groups = {PhD/AI competency project},
number = {1},
pages = {61--65},
publisher = {Springer International Publishing},
title = {{Emerging challenges in AI and the need for AI ethics education}},
url = {https://doi.org/10.1007/s43681-020-00002-7},
volume = {1},
year = {2020}
}
@inproceedings{Madaio2020,
abstract = {Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to oper-ationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts , such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We discuss aspects of organizational culture that may impact the efficacy of such checklists, and highlight future research directions.},
author = {Madaio, Michael A. and Stark, Luke and {Wortman Vaughan}, Jennifer and Wallach, Hanna},
booktitle = {Comput. Hum. Interact.},
doi = {10.1145/3313831.3376445},
file = {:C$\backslash$:/Users/shala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Madaio et al. - 2020 - Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI.pdf:pdf},
isbn = {9781450367080},
keywords = {"AI,ML,checklists",co-design,ethics,fairness},
mendeley-groups = {PhD/AI competency project},
pages = {1--14},
title = {{Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI}},
year = {2020}
}
@article{Raji2020a,
abstract = {Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source. In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development lifecycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.},
archivePrefix = {arXiv},
arxivId = {2001.00973},
author = {Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N. and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and Smith-Loud, Jamila and Theron, Daniel and Barnes, Parker},
doi = {10.1145/3351095.3372873},
eprint = {2001.00973},
file = {:C$\backslash$:/Users/shala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Raji et al. - 2020 - Closing the AI accountability gap Defining an end-to-end framework for internal algorithmic auditing.pdf:pdf},
isbn = {9781450369367},
journal = {FAT* 2020 - Proc. 2020 Conf. Fairness, Accountability, Transpar.},
keywords = {Accountability,Algorithmic audits,Machine learning,Responsible innovation},
mendeley-groups = {PhD/AI Ethics Metrics Paper/Acct/Resp,PhD/AI competency project},
pages = {33--44},
title = {{Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing}},
year = {2020}
}
@article{Jobin2019,
abstract = {In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be ‘ethical', there is debate about both what constitutes ‘ethical AI' and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies. As AI technology develops rapidly, it is widely recognized that ethical guidelines are required for safe and fair implementation in society. But is it possible to agree on what is ‘ethical AI'? A detailed analysis of 84 AI ethics reports around the world, from national and international organizations, companies and institutes, explores this question, finding a convergence around core principles but substantial divergence on practical implementation.},
author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
doi = {10.1038/s42256-019-0088-2},
file = {:C$\backslash$:/Users/shala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jobin, Ienca, Vayena - 2019 - The global landscape of AI ethics guidelines.pdf:pdf},
isbn = {4225601900},
issn = {2522-5839},
journal = {Nat. Mach. Intell.},
mendeley-groups = {PhD,ECSE 681,PhD/AI competency project},
number = {9},
pages = {389--399},
publisher = {Springer US},
title = {{The global landscape of AI ethics guidelines}},
url = {http://dx.doi.org/10.1038/s42256-019-0088-2},
volume = {1},
year = {2019},
}
@misc{Moon2019,
author = {Moon, AJung and Rismani, Shalaleh and Millar, Jason and Forsyth, Terralynn and Eshpeter, Jordan and Jaffar, Muhammad and Phan, Anh},
file = {:G$\backslash$:/My Drive/PhD/AI Competency Project/Literature Review/ORI-Foresight-into-Artificial-Intelligence-Ethics-Launch-V1.pdf:pdf},
mendeley-groups = {PhD/AI competency project},
number = {October},
publisher = {Open Roboethics Institute},
title = {{Foresight into AI Ethics}},
year = {2019},
}

@misc{Andersona,
author = {Anderson, David and Bonaguro, Joy and McKinney, Miriam and Nicklin, Andrew and Wiseman, Jane},
mendeley-groups = {PhD/AI competency project},
title = {{Ethics and algorithms toolkit}},
url = {https://ethicstoolkit.ai/},
year = {2020}
}

@misc{cipd,
booktitle = {CIPD},
mendeley-groups = {PhD/AI competency project},
title = {{Competence and competency frameworks - factsheets - CIPD}},
url = {https://www.cipd.co.uk/knowledge/fundamentals/people/performance/competency-factsheet},
year = {2021}

}

@misc{ieee,
booktitle = {IEEE},
mendeley-groups = {PhD/AI competency project},
title = {{IEEE Ethics in Action in Autonomous and Intelligent Systems}},
year = {2022}
}

@article{eu,
booktitle = {Eur. Comm.},
mendeley-groups = {PhD/AI competency project},
title = {{A European approach to artificial intelligence - shaping Europe's digital future}},
url = {https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence},
year = {2021}
}

@article{microsoft,
booktitle = {Microsoft AI},
mendeley-groups = {PhD/AI competency project},
title = {{Responsible AI resources}},
url = {https://www.microsoft.com/en-us/ai/responsible-ai-resources},
year = {2022}
}

@article{ibm,
booktitle = {IBM},
mendeley-groups = {PhD/AI competency project},
title = {{AI Ethics Toolkit}},
url = {https://www.ibm.com/artificial-intelligence/ethics},
year = {2022}
}

@misc{canada,
booktitle = {Gov. Canada},
mendeley-groups = {PhD/AI competency project},
title = {{Algorithmic Impact Assessment}},
url = {https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/responsible-use-ai/algorithmic-impact-assessment.html},
year = {2022}
}


@book{Sanghi2016,
author = {Sanghi, Seema},
edition = {3e},
mendeley-groups = {PhD/AI competency project},
publisher = {SAGE},
title = {{The handbook of competency mapping}},
year = {2016}
}

@book{Spencer1993,
address = {New York},
author = {Spencer, L.M. and Spencer, S.M.},
mendeley-groups = {PhD/AI competency project},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Competence at Work - Models for Superior Performance}},
year = {1993}
}
@misc{EuropeanCommission2022,
author = {{European Commission}},
mendeley-groups = {PhD/AI competency project},
title = {{The ESCO Classification}},
url = {https://esco.ec.europa.eu/en/classification},
year = {2022}
}
@misc{Administration,
author = {Administration, Employment {\&} Training},
mendeley-groups = {PhD/AI competency project},
title = {{O*NET database Content Model}},
url = {https://www.onetcenter.org/content.html},
year = {2022}
}

@ARTICLE{Heger2022-eo,
  title     = "Understanding Machine Learning Practitioners' Data Documentation
               Perceptions, Needs, Challenges, and Desiderata",
  author    = "Heger, Amy K and Marquis, Liz B and Vorvoreanu, Mihaela and
               Wallach, Hanna and Wortman Vaughan, Jennifer",
  abstract  = "Data is central to the development and evaluation of machine
               learning (ML) models. However, the use of problematic or
               inappropriate datasets can result in harms when the resulting
               models are deployed. To encourage responsible AI practice
               through more deliberate reflection on datasets and transparency
               around the processes by which they are created, researchers and
               practitioners have begun to advocate for increased data
               documentation and have proposed several data documentation
               frameworks. However, there is little research on whether these
               data documentation frameworks meet the needs of ML
               practitioners, who both create and consume datasets. To address
               this gap, we set out to understand ML practitioners' data
               documentation perceptions, needs, challenges, and desiderata,
               with the ultimate goal of deriving design requirements that can
               inform future data documentation frameworks. We conducted a
               series of semi-structured interviews with 14 ML practitioners at
               a single large, international technology company. We had them
               answer a list of questions taken from datasheets for
               datasets~\textbackslashcitegebru2018datasheets. Our findings
               show that current approaches to data documentation are largely
               ad hoc and myopic in nature. Participants expressed needs for
               data documentation frameworks to be adaptable to their contexts,
               integrated into their existing tools and workflows, and
               automated wherever possible. Despite the fact that data
               documentation frameworks are often motivated from the
               perspective of responsible AI, participants did not make the
               connection between the questions that they were asked to answer
               and their responsible AI implications. In addition, participants
               often had difficulties prioritizing the needs of dataset
               consumers and providing information that someone unfamiliar with
               their datasets might need to know. Based on these findings, we
               derive seven design requirements for future data documentation
               frameworks such as more actionable guidance on how the
               characteristics of datasets might result in harms and how these
               harms might be mitigated, more explicit prompts for reflection,
               automated adaptation to different contexts, and integration into
               ML practitioners' existing tools and workflows.",
  journal   = "Proc. ACM Hum.-Comput. Interact.",
  publisher = "Association for Computing Machinery",
  volume    =  6,
  number    = "CSCW2",
  pages     = "1--29",
  month     =  nov,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "responsible AI, documentation, machine learning, datasets"
}

@ARTICLE{Mantymaki2022-im,
  title         = "Putting {AI} Ethics into Practice: The Hourglass Model of
                   Organizational {AI} Governance",
  author        = "M{\"a}ntym{\"a}ki, Matti and Minkkinen, Matti and Birkstedt,
                   Teemu and Viljanen, Mika",
  abstract      = "The organizational use of artificial intelligence (AI) has
                   rapidly spread across various sectors. Alongside the
                   awareness of the benefits brought by AI, there is a growing
                   consensus on the necessity of tackling the risks and
                   potential harms, such as bias and discrimination, brought
                   about by advanced AI technologies. A multitude of AI ethics
                   principles have been proposed to tackle these risks, but the
                   outlines of organizational processes and practices for
                   ensuring socially responsible AI development are in a
                   nascent state. To address the paucity of comprehensive
                   governance models, we present an AI governance framework,
                   the hourglass model of organizational AI governance, which
                   targets organizations that develop and use AI systems. The
                   framework is designed to help organizations deploying AI
                   systems translate ethical AI principles into practice and
                   align their AI systems and processes with the forthcoming
                   European AI Act. The hourglass framework includes governance
                   requirements at the environmental, organizational, and AI
                   system levels. At the AI system level, we connect governance
                   requirements to AI system life cycles to ensure governance
                   throughout the system's life span. The governance model
                   highlights the systemic nature of AI governance and opens
                   new research avenues into its practical implementation, the
                   mechanisms that connect different AI governance layers, and
                   the dynamics between the AI governance actors. The model
                   also offers a starting point for organizational
                   decision-makers to consider the governance components needed
                   to ensure social acceptability, mitigate risks, and realize
                   the potential of AI.",
  month         =  jun,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2206.00335"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Atkins2021-ei,
  title     = "Applying Ethical {AI} Frameworks in practice: Evaluating
               conversational {AI} chatbot solutions",
  author    = "Atkins, Suzanne and Badrie, Ishwarradj and van Otterloo,
               Sieuwert",
  abstract  = "… frameworks, we evaluated four commercial chatbots against four
               responsible AI frameworks. We found that the ethical frameworks
               produced quite di erent assessment scores. Many ethi…",
  journal   = "Behav. Res. Methods Instrum. Comput.",
  publisher = "researchgate.net",
  year      =  2021
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wang2023-js,
  title     = "Designing responsible {AI}: Adaptations of {UX} practice to meet
               responsible {AI} challenges",
  author    = "Wang, Qiaosi and Madaio, Michael Adam and Kapania, Shivani and
               Kane, Shaun and Terry, Michael and Wilcox, Lauren",
  abstract  = "… ized in practice across sectors and organizations [61]. We use
               the term `` responsible AI '' by its … primarily opted to defne
               responsible AI in terms of the practices they used to enact it,
               rather …",
  publisher = "research.google",
  year      =  2023
}

@TECHREPORT{Pak-Hang_Wong2020-jv,
  title    = "Thinking About `Ethics' in the Ethics of {AI}",
  author   = "Pak-Hang Wong, Judith Simon",
  month    =  feb,
  year     =  2020
}

@ARTICLE{Widder2023-lh,
  title     = "Dislocated accountabilities in the {``AI} supply chain'':
               Modularity and developers' notions of responsibility",
  author    = "Widder, David Gray and Nafus, Dawn",
  abstract  = "Responsible artificial intelligence guidelines ask engineers to
               consider how their systems might harm. However, contemporary
               artificial intelligence systems are built by composing many
               preexisting software modules that pass through many hands before
               becoming a finished product or service. How does this shape
               responsible artificial intelligence practice? In interviews with
               27 artificial intelligence engineers across industry, open
               source, and academia, our participants often did not see the
               questions posed in responsible artificial intelligence
               guidelines to be within their agency, capability, or
               responsibility to address. We use Suchman's ?located
               accountability? to show how responsible artificial intelligence
               labor is currently organized and to explore how it could be done
               differently. We identify cross-cutting social logics, like
               modularizability, scale, reputation, and customer orientation,
               that organize which responsible artificial intelligence actions
               do take place and which are relegated to low status staff or
               believed to be the work of the next or previous person in the
               imagined ?supply chain.? We argue that current responsible
               artificial intelligence interventions, like ethics checklists
               and guidelines that assume panoptical knowledge and control over
               systems, could be improved by taking a located accountability
               approach, recognizing where relations and obligations might
               intertwine inside and outside of this supply chain.",
  journal   = "Big Data \& Society",
  publisher = "SAGE Publications Ltd",
  volume    =  10,
  number    =  1,
  pages     = "20539517231177620",
  month     =  jan,
  year      =  2023
}


@ARTICLE{Figueras2022-dm,
  title     = "Exploring tensions in Responsible {AI} in practice. An interview
               study on {AI} practices in and for Swedish public organizations",
  author    = "Figueras, Cl{\`a}udia and Verhagen, Harko and Pargman, Teresa
               Cerratto",
  abstract  = "The increasing use of Artificial Intelligence (AI) systems has
               sparked discussions regarding developing ethically responsible
               technology. Consequently, various organizations have released
               high-level AI ethics frameworks to assist in AI design. However,
               we still know too little about how AI ethics principles are
               perceived and work in practice, especially in public
               organizations. This study examines how AI practitioners perceive
               ethical issues in their work concerning AI design and how they
               interpret and put them into practice. We conducted an empirical
               study consisting of semi-structured qualitative interviews with
               AI practitioners working in or for public organizations. Taking
               the lens provided by the In-Action Ethics framework and previous
               studies on ethical tensions, we analyzed practitioners'
               interpretations of AI ethics principles and their application in
               practice. We found tensions between practitioners'
               interpretation of ethical principles in their work and ethos
               tensions. In this vein, we argue that understanding the
               different tensions that can occur in practice and how they are
               tackled is key to studying ethics in practice. Understanding how
               AI practitioners perceive and apply ethical principles is
               necessary for practical ethics to contribute toward an
               empirically grounded, Responsible AI.",
  journal   = "Scandinavian Journal of Information Systems",
  publisher = "aisel.aisnet.org",
  volume    =  34,
  number    =  2,
  pages     = "6",
  year      =  2022
}

@ARTICLE{Nabavi2023-ce,
  title     = "Leverage zones in Responsible {AI}: towards a systems thinking
               conceptualization",
  author    = "Nabavi, Ehsan and Browne, Chris",
  abstract  = "There is a growing debate amongst academics and practitioners on
               whether interventions made, thus far, towards Responsible AI
               have been enough to engage with the root causes of AI problems.
               Failure to effect meaningful changes in this system could see
               these initiatives not reach their potential and lead to the
               concept becoming another buzzword for companies to use in their
               marketing campaigns. Systems thinking is often touted as a
               methodology to manage and effect change; however, there is
               little practical advice available for decision-makers to include
               systems thinking insights to work towards Responsible AI. Using
               the notion of `leverage zones' adapted from the systems thinking
               literature, we suggest a novel approach to plan for and
               experiment with potential initiatives and interventions. This
               paper presents a conceptual framework called the Five Ps to help
               practitioners construct and identify holistic interventions that
               may work towards Responsible AI, from lower-order interventions
               such as short-term fixes, tweaking algorithms and updating
               parameters, through to higher-order interventions such as
               redefining the system's foundational structures that govern
               those parameters, or challenging the underlying purpose upon
               which those structures are built and developed in the first
               place. Finally, we reflect on the framework as a scaffold for
               transdisciplinary question-asking to improve outcomes towards
               Responsible AI.",
  journal   = "Humanities and Social Sciences Communications",
  publisher = "Palgrave",
  volume    =  10,
  number    =  1,
  pages     = "1--9",
  month     =  mar,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Schiff2020-mq,
  title         = "Principles to Practices for Responsible {AI}: Closing the
                   Gap",
  author        = "Schiff, Daniel and Rakova, Bogdana and Ayesh, Aladdin and
                   Fanti, Anat and Lennon, Michael",
  abstract      = "Companies have considered adoption of various high-level
                   artificial intelligence (AI) principles for responsible AI,
                   but there is less clarity on how to implement these
                   principles as organizational practices. This paper reviews
                   the principles-to-practices gap. We outline five
                   explanations for this gap ranging from a disciplinary divide
                   to an overabundance of tools. In turn, we argue that an
                   impact assessment framework which is broad,
                   operationalizable, flexible, iterative, guided, and
                   participatory is a promising approach to close the
                   principles-to-practices gap. Finally, to help practitioners
                   with applying these recommendations, we review a case study
                   of AI's use in forest ecosystem restoration, demonstrating
                   how an impact assessment framework can translate into
                   effective and responsible AI practices.",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY",
  eprint        = "2006.04707"
}

@INPROCEEDINGS{Deshpande2022-rv,
  title     = "Responsible {AI} Systems: Who are the Stakeholders?",
  booktitle = "Proceedings of the 2022 {AAAI/ACM} Conference on {AI}, Ethics,
               and Society",
  author    = "Deshpande, Advait and Sharp, Helen",
  abstract  = "As of 2021, there were more than 170 guidelines on AI ethics and
               responsible, trustworthy AI in circulation according to the AI
               Ethics Guidelines Global Inventory maintained by AlgorithmWatch,
               an organisation which tracks the effects of increased
               digitalisation on everyday lives. However, from the perspective
               of day-to-day work, for those engaged in designing, developing,
               and maintaining AI systems identifying relevant guidelines and
               translating them into practice presents a challenge.The aim of
               this paper is to help anyone engaged in building a responsible
               AI system by identifying an indicative long-list of potential
               stakeholders. This list of impacted stakeholders is intended to
               enable such AI system builders to decide which guidelines are
               most suited to their practice. The paper draws on a literature
               review of articles short-listed based on searches conducted in
               the ACM Digital Library and Google Scholar. The findings are
               based on content analysis of the short-listed literature guided
               by probes which draw on the ISO 26000:2010 Guidance on social
               responsibility.The paper identifies three levels of potentially
               relevant stakeholders when responsible AI systems are
               considered: individual stakeholders (including users,
               developers, and researchers), organisational stakeholders, and
               national / international stakeholders engaged in making laws,
               rules, and regulations. The main intended audience for this
               paper is software, requirements, and product engineers engaged
               in building AI systems. In addition, business executives, policy
               makers, legal/regulatory experts, AI researchers, public,
               private, and third sector organisations developing responsible
               AI guidelines, and anyone interested in seeing functional
               responsible AI systems are the other intended audience for this
               paper.",
  publisher = "Association for Computing Machinery",
  pages     = "227--236",
  series    = "AIES '22",
  month     =  jul,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "ISO 26000:2010 guidance on social responsibility, AI system
               builders, responsible AI systems, AI ethics, corporate social
               responsibility, stakeholder identification",
  location  = "Oxford, United Kingdom"
}

@MISC{Heger_undated-ke,
  title        = "All the tools, none of the motivation: Organizational culture
                  and barriers to responsible {AI} work",
  author       = "Heger, Amy and Passi, Samir and Vorvoreanu, Mihaela",
  abstract     = "As applications of artificial intelligence (AI) have
                  proliferated so too have ethical concerns regarding their
                  potential to cause harm to society. As a result, many
                  organizations that build or use AI systems have developed
                  frameworks or codes of conduct specifying ethical or
                  responsible AI principles they strive to follow (e.g.",
  howpublished = "\url{https://ai-cultures.github.io/papers/all_the_tools_none_of_the_moti.pdf}",
  note         = "Accessed: 2023-3-11"
}

@ARTICLE{Schiff2021-et,
  title     = "Explaining the Principles to Practices Gap in {AI}",
  author    = "Schiff, Daniel and Rakova, Bogdana and Ayesh, Aladdin and Fanti,
               Anat and Lennon, Michael",
  abstract  = "As artificial intelligence (AI) permeates across social and
               economic life, its ethical and governance implications have come
               to the forefront. Active debates surround AI's role in labor
               displacement, autonomous vehicles, military, misinformation,
               healthcare, education, and more. As societies collectively
               grapple with these challenges, new opportunities for AI to
               proactively contribute to social good (AI4SG) and equity (AI4Eq)
               have also been proposed [1], [2], such as Microsoft's AI for
               Earth program. These efforts highlight the potential of AI to
               address global challenges and help achieve targets like the
               United Nation's sustainable development goals (SDGs) [3]. Yet,
               whether AI efforts are directed explicitly at social good and
               equity or not, there are many barriers that stand between
               aspirations to be responsible and the translation of these
               aspirations into concrete practicalities.",
  journal   = "IEEE Technol. Soc. Mag.",
  publisher = "ieeexplore.ieee.org",
  volume    =  40,
  number    =  2,
  pages     = "81--94",
  month     =  jun,
  year      =  2021,
  keywords  = "Economics;Social factors;Education;Medical services;Artificial
               intelligence;Sustainable development;Autonomous vehicles"
}

@ARTICLE{Rakova2021-dg,
  title     = "Where Responsible {AI} meets Reality: Practitioner Perspectives
               on Enablers for Shifting Organizational Practices",
  author    = "Rakova, Bogdana and Yang, Jingying and Cramer, Henriette and
               Chowdhury, Rumman",
  abstract  = "Large and ever-evolving technology companies continue to invest
               more time and resources to incorporate responsible Artificial
               Intelligence (AI) into production-ready systems to increase
               algorithmic accountability. This paper examines and seeks to
               offer a framework for analyzing how organizational culture and
               structure impact the effectiveness of responsible AI initiatives
               in practice. We present the results of semi-structured
               qualitative interviews with practitioners working in industry,
               investigating common challenges, ethical tensions, and effective
               enablers for responsible AI initiatives. Focusing on major
               companies developing or utilizing AI, we have mapped what
               organizational structures currently support or hinder
               responsible AI initiatives, what aspirational future processes
               and structures would best enable effective initiatives, and what
               key elements comprise the transition from current work practices
               to the aspirational future.",
  journal   = "Proc. ACM Hum.-Comput. Interact.",
  publisher = "Association for Computing Machinery",
  volume    =  5,
  number    = "CSCW1",
  pages     = "1--23",
  month     =  apr,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "responsible ai, organizational structure, industry practice"
}

@ARTICLE{Dignum2021-xt,
  title     = "The role and challenges of education for responsible {AI}",
  author    = "Dignum, Virginia",
  abstract  = "Artificial intelligence (AI) is impacting education in many
               different ways. From virtual assistants for personalized
               education, to student or teacher tracking systems, the potential
               benefits of AI for education often come with a discussion of its
               impact on privacy and well-being. At the same time, the social
               transformation brought about by AI requires reform of
               traditional education systems. This article discusses what a
               responsible, trustworthy vision for AI is and how this relates
               to and affects education.",
  journal   = "Lond. Rev. Educ.",
  publisher = "UCL Press",
  volume    =  19,
  number    =  1,
  month     =  jan,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Gambelin2021-rh,
  title    = "Brave: what it means to be an {AI} Ethicist",
  author   = "Gambelin, Olivia",
  abstract = "Despite there being a strong call for responsible technology, the
              path towards putting ethics into action is still yet to be fully
              understood. To help guide the implementation of ethics, we have
              seen the rise of a new professional title; the AI Ethicist.
              However, it is still unclear what the role and skill set of this
              new profession must include. The purpose of this piece is to
              offer a preliminary definition of what it means to be an AI
              Ethicist by first examining the concept of an ethicist in the
              context of artificial intelligence, followed by exploring what
              responsibilities are added to the role in industry specifically,
              and ending on the fundamental characteristic that underlies it
              all: bravery.",
  journal  = "AI and Ethics",
  volume   =  1,
  number   =  1,
  pages    = "87--91",
  month    =  feb,
  year     =  2021
}

@ARTICLE{Peterson2023-xa,
  title     = "Abstracted Power and Responsibility in Computer Science Ethics
               Education",
  author    = "Peterson, Tina L and Ferreira, Rodrigo and Vardi, Moshe Y",
  abstract  = "As computing becomes more powerful and extends the reach of
               those who wield it, the imperative grows for computing
               professionals to make ethical decisions regarding the use of
               that power. We propose the concept of abstracted power to help
               computer science students understand how technology may distance
               them perceptually from consequences of their actions.
               Specifically, we identify technological intermediation and
               computational thinking as two factors in computer science that
               contribute to this distancing. To counter the abstraction of
               power, we argue for increased emotional engagement in computer
               science ethics education, to encourage students to feel as well
               as think regarding the potential impacts of their power on
               others. We suggest four concrete pedagogical approaches to
               enable this emotional engagement in computer science ethics
               curriculum, and we share highlights of student reactions to the
               material.",
  journal   = "IEEE Transactions on Technology and Society",
  publisher = "ieeexplore.ieee.org",
  pages     = "1--1",
  year      =  2023,
  keywords  = "Ethics;Computer
               science;Writing;Faces;Cognition;Codes;Philosophical
               considerations;power;abstraction;responsibility;social
               impact;emotional engagement;ethics"
}

@ARTICLE{Ryan2022-ej,
  title     = "An {AI} ethics `David and Goliath': value conflicts between
               large tech companies and their employees",
  author    = "Ryan, Mark and Christodoulou, Eleni and Antoniou, Josephina and
               Iordanou, Kalypso",
  abstract  = "AbstractArtificial intelligence ethics requires a united
               approach from policymakers, AI companies, and individuals, in
               the development, deployment, and use of these technologies.
               However, sometimes discussions can become fragmented because of
               the different levels of governance (Schmitt in AI Ethics 1--12,
               2021) or because of different values, stakeholders, and actors
               involved (Ryan and Stahl in J Inf Commun Ethics Soc 19:61--86,
               2021). Recently, these conflicts became very visible, with such
               examples as the dismissal of AI ethics researcher Dr. Timnit
               Gebru from Google and the resignation of whistle-blower Frances
               Haugen from Facebook. Underpinning each debacle was a conflict
               between the organisation's economic and business interests and
               the morals of their employees. This paper will examine tensions
               between the ethics of AI organisations and the values of their
               employees, by providing an exploration of the AI ethics
               literature in this area, and a qualitative analysis of three
               workshops with AI developers and practitioners. Common ethical
               and social tensions (such as power asymmetries, mistrust,
               societal risks, harms, and lack of transparency) will be
               discussed, along with proposals on how to avoid or reduce these
               conflicts in practice (e.g., building trust, fair allocation of
               responsibility, protecting employees' autonomy, and encouraging
               ethical training and practice). Altogether, we suggest the
               following steps to help reduce ethical issues within AI
               organisations: improved and diverse ethics education and
               training within businesses; internal and external ethics
               auditing; the establishment of AI ethics ombudsmen, AI ethics
               review committees and an AI ethics watchdog; as well as access
               to trustworthy AI ethics whistle-blower organisations.",
  journal   = "AI Soc.",
  publisher = "Springer Science and Business Media LLC",
  month     =  mar,
  year      =  2022,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Gorur2020-vu,
  title       = "Computer Science Ethics Education in {Australia--A} Work in
                 Progress",
  booktitle   = "2020 {IEEE} International Conference on Teaching, Assessment,
                 and Learning for Engineering ({TALE})",
  author      = "Gorur, Radhika and Hoon, Leonard and Kowal, Emma",
  abstract    = "… the key ethical requirements for AI development and … in AI
                 environments are well aware of potential consequences of the
                 technologies they develop and deploy, sensitive to the ethical
                 …",
  publisher   = "ieeexplore.ieee.org",
  pages       = "945--947",
  institution = "IEEE",
  year        =  2020
}

@ARTICLE{Williams2020-ar,
  title     = "An Experimental Ethics Approach to Robot Ethics Education",
  author    = "Williams, Tom and Zhu, Qin and Grollman, Daniel",
  abstract  = "We propose an experimental ethics-based curricular module for an
               undergraduate course on Robot Ethics. The proposed module aims
               to teach students how human subjects research methods can be
               used to investigate potential ethical concerns arising in
               human-robot interaction, by engaging those students in real
               experimental ethics research. In this paper we describe the
               proposed curricular module, describe our implementation of that
               module within a Robot Ethics course offered at a medium-sized
               engineering university, and statistically evaluate the
               effectiveness of the proposed curricular module in achieving
               desired learning objectives. While our results do not provide
               clear evidence of a quantifiable benefit to undergraduate
               achievement of the described learning objectives, we note that
               the module did provide additional learning opportunities for
               graduate students in the course, as they helped to supervise,
               analyze, and write up the results of this
               undergraduate-performed research experiment.",
  journal   = "AAAI",
  publisher = "ojs.aaai.org",
  volume    =  34,
  number    =  09,
  pages     = "13428--13435",
  month     =  apr,
  year      =  2020,
  language  = "en"
}

@INPROCEEDINGS{Williams2021-sd,
  title     = "How to Train Your Robot: {Project-Based} {AI} and Ethics
               Education for Middle School Classrooms",
  booktitle = "Proceedings of the 52nd {ACM} Technical Symposium on Computer
               Science Education",
  author    = "Williams, Randi",
  abstract  = "We developed the How to Train Your Robot curriculum to empower
               middle school students to become conscientious users and
               creators of Artificial Intelligence (AI). As AI becomes more
               embedded in our daily lives, all members of society should have
               the opportunity to become AI literate. Today, most deployed work
               in K-12 AI education takes place at strong STEM schools or
               during extracurricular clubs. But, to promote equity in the
               field of AI, we must also design curricula for classroom use at
               schools with limited resources. How to Train Your Robot
               leverages a low-cost (\$40) robot, a block-based programming
               platform, novice-friendly model creation tools, and hands-on
               activities to introduce students to machine learning. During the
               summer of 2020, we trained in-service teachers, primarily from
               Title 1 public schools, to deliver a five-day, online version of
               the curriculum to their students. In this work, we describe how
               students' self-directed final projects demonstrate their
               understanding of technical and ethical AI concepts. Students
               successfully selected project ideas, taking the strengths and
               weaknesses of machine learning into account, and implemented an
               array of projects about everything from entertainment to
               science. We saw that students had the most difficulty designing
               mechanisms to respond to user feedback after deployment. We hope
               this work inspires future AI curricula that can be used in
               middle school classrooms.",
  publisher = "Association for Computing Machinery",
  pages     = "1382",
  series    = "SIGCSE '21",
  month     =  mar,
  year      =  2021,
  address   = "New York, NY, USA",
  keywords  = "middle school, cs education, machine learning, ai literacy",
  location  = "Virtual Event, USA"
}

@ARTICLE{Quinn2021-jj,
  title         = "Readying Medical Students for Medical {AI}: The Need to
                   Embed {AI} Ethics Education",
  author        = "Quinn, Thomas P and Coghlan, Simon",
  abstract      = "Medical students will almost inevitably encounter powerful
                   medical AI systems early in their careers. Yet, contemporary
                   medical education does not adequately equip students with
                   the basic clinical proficiency in medical AI needed to use
                   these tools safely and effectively. Education reform is
                   urgently needed, but not easily implemented, largely due to
                   an already jam-packed medical curricula. In this article, we
                   propose an education reform framework as an effective and
                   efficient solution, which we call the Embedded AI Ethics
                   Education Framework. Unlike other calls for education reform
                   to accommodate AI teaching that are more radical in scope,
                   our framework is modest and incremental. It leverages
                   existing bioethics or medical ethics curricula to develop
                   and deliver content on the ethical issues associated with
                   medical AI, especially the harms of technology misuse,
                   disuse, and abuse that affect the risk-benefit analyses at
                   the heart of healthcare. In doing so, the framework provides
                   a simple tool for going beyond the ``What?'' and the
                   ``Why?'' of medical AI ethics education, to answer the
                   ``How?'', giving universities, course directors, and/or
                   professors a broad road-map for equipping their students
                   with the necessary clinical proficiency in medical AI.",
  month         =  sep,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI",
  eprint        = "2109.02866"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Garrett2020-dw,
  title      = "More than ``if time allows'': The Role of Ethics in {AI}
                Education",
  booktitle  = "Proceedings of the {AAAI/ACM} Conference on {AI}, Ethics, and
                Society",
  author     = "Garrett, Natalie and Beard, Nathan and Fiesler, Casey",
  abstract   = "… Therefore, to explore one component of the current state of
                AI ethics education , we examine a sample of these classes for
                patterns in what topics are currently being taught. …",
  publisher  = "ACM",
  month      =  feb,
  year       =  2020,
  address    = "New York, NY, USA",
  conference = "AIES '20: AAAI/ACM Conference on AI, Ethics, and Society",
  location   = "New York NY USA"
}

@INPROCEEDINGS{Raji2021-ih,
  title     = "You Can't Sit With Us: Exclusionary Pedagogy in {AI} Ethics
               Education",
  booktitle = "Proceedings of the 2021 {ACM} Conference on Fairness,
               Accountability, and Transparency",
  author    = "Raji, Inioluwa Deborah and Scheuerman, Morgan Klaus and
               Amironesei, Razvan",
  abstract  = "Given a growing concern about the lack of ethical consideration
               in the Artificial Intelligence (AI) field, many have begun to
               question how dominant approaches to the disciplinary education
               of computer science (CS)---and its implications for AI---has led
               to the current ``ethics crisis''. However, we claim that the
               current AI ethics education space relies on a form of
               ``exclusionary pedagogy,'' where ethics is distilled for
               computational approaches, but there is no deeper epistemological
               engagement with other ways of knowing that would benefit ethical
               thinking or an acknowledgement of the limitations of uni-vocal
               computational thinking. This results in indifference,
               devaluation, and a lack of mutual support between CS and
               humanistic social science (HSS), elevating the myth of
               technologists as ``ethical unicorns'' that can do it all, though
               their disciplinary tools are ultimately limited. Through an
               analysis of computer science education literature and a review
               of college-level course syllabi in AI ethics, we discuss the
               limitations of the epistemological assumptions and hierarchies
               of knowledge which dictate current attempts at including ethics
               education in CS training and explore evidence for the practical
               mechanisms through which this exclusion occurs. We then propose
               a shift towards a substantively collaborative, holistic, and
               ethically generative pedagogy in AI education.",
  publisher = "Association for Computing Machinery",
  pages     = "515--525",
  series    = "FAccT '21",
  month     =  mar,
  year      =  2021,
  address   = "New York, NY, USA",
  location  = "Virtual Event, Canada"
}

@ARTICLE{Furey2019-xz,
  title     = "{AI} education matters: a modular approach to {AI} ethics
               education",
  author    = "Furey, Heidi and Martin, Fred",
  abstract  = "In this column, we introduce our Model AI Assignment, A Module
               on Ethical Thinking about Autonomous Vehicles in an AI Course,
               and more broadly introduce a conversation on ethics education in
               AI education.",
  journal   = "AI Matters",
  publisher = "Association for Computing Machinery",
  volume    =  4,
  number    =  4,
  pages     = "13--15",
  month     =  jan,
  year      =  2019,
  address   = "New York, NY, USA"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Borenstein2021-kf,
  title     = "Emerging challenges in {AI} and the need for {AI} ethics
               education",
  author    = "Borenstein, Jason and Howard, Ayanna",
  abstract  = "… approaches to AI ethics and offer a set of recommendations
               related to AI ethics pedagogy. … Within this realm, we highlight
               recent approaches to AI ethics education , especially as they …",
  journal   = "AI Ethics",
  publisher = "Springer Science and Business Media LLC",
  volume    =  1,
  number    =  1,
  pages     = "61--65",
  month     =  feb,
  year      =  2021,
  language  = "en"
}

@INPROCEEDINGS{Costanza-Chock2022-ch,
  title     = "Who Audits the Auditors? Recommendations from a field scan of
               the algorithmic auditing ecosystem",
  booktitle = "2022 {ACM} Conference on Fairness, Accountability, and
               Transparency",
  author    = "Costanza-Chock, Sasha and Raji, Inioluwa Deborah and Buolamwini,
               Joy",
  abstract  = "Algorithmic audits (or `AI audits') are an increasingly popular
               mechanism for algorithmic accountability; however, they remain
               poorly defined. Without a clear understanding of audit
               practices, let alone widely used standards or regulatory
               guidance, claims that an AI product or system has been audited,
               whether by first-, second-, or third-party auditors, are
               difficult to verify and may potentially exacerbate, rather than
               mitigate, bias and harm. To address this knowledge gap, we
               provide the first comprehensive field scan of the AI audit
               ecosystem. We share a catalog of individuals (N=438) and
               organizations (N=189) who engage in algorithmic audits or whose
               work is directly relevant to algorithmic audits; conduct an
               anonymous survey of the group (N=152); and interview industry
               leaders (N=10). We identify emerging best practices as well as
               methods and tools that are becoming commonplace, and enumerate
               common barriers to leveraging algorithmic audits as effective
               accountability mechanisms. We outline policy recommendations to
               improve the quality and impact of these audits, and highlight
               proposals with wide support from algorithmic auditors as well as
               areas of debate. Our recommendations have implications for
               lawmakers, regulators, internal company policymakers, and
               standards-setting bodies, as well as for auditors. They are: 1)
               require the owners and operators of AI systems to engage in
               independent algorithmic audits against clearly defined
               standards; 2) notify individuals when they are subject to
               algorithmic decision-making systems; 3) mandate disclosure of
               key components of audit findings for peer review; 4) consider
               real-world harm in the audit process, including through
               standardized harm incident reporting and response mechanisms; 5)
               directly involve the stakeholders most likely to be harmed by AI
               systems in the algorithmic audit process; and 6) formalize
               evaluation and, potentially, accreditation of algorithmic
               auditors.",
  publisher = "Association for Computing Machinery",
  pages     = "1571--1583",
  series    = "FAccT '22",
  month     =  jun,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "algorithm audit, ethical AI, AI bias, AI audit, audit,
               algorithmic accountability, AI policy, AI harm",
  location  = "Seoul, Republic of Korea"
}

@INPROCEEDINGS{Sloane2022-ag,
  title     = "German {AI} {Start-Ups} and {``AI} Ethics'': Using A Social
               Practice Lens for Assessing and Implementing {Socio-Technical}
               Innovation",
  booktitle = "2022 {ACM} Conference on Fairness, Accountability, and
               Transparency",
  author    = "Sloane, Mona and Zakrzewski, Janina",
  abstract  = "The current AI ethics discourse focuses on developing
               computational interpretations of ethical concerns, normative
               frameworks, and concepts for socio-technical innovation. There
               is less emphasis on understanding how AI practitioners
               themselves understand ethics and socially organize to
               operationalize ethical concerns. This is particularly true for
               AI start-ups, despite their significance as a conduit for the
               cultural production of innovation and progress, especially in
               the US and European context. This gap in empirical research
               intensifies the risk of a disconnect between scholarly research,
               innovation and application. This risk materializes acutely as
               mounting pressures to identify and mitigate the potential harms
               of AI systems have created an urgent need to rapidly assess and
               implement socio-technical innovation focused on fairness,
               accountability, and transparency. In this paper, we address this
               need. Building on social practice theory, we propose a framework
               that allows AI researchers, practitioners, and regulators to
               systematically analyze existing cultural understandings,
               histories, and social practices of ``ethical AI'' to define
               appropriate strategies for effectively implementing
               socio-technical innovations. We argue that this approach is
               needed because socio-technical innovation ``sticks'' better if
               it sustains the cultural meaning of socially shared (ethical) AI
               practices, rather than breaking them. By doing so, it creates
               pathways for technical and socio-technical innovations to be
               integrated into already existing routines. Against that
               backdrop, our contributions are threefold: (1) we introduce a
               practice-based approach for understanding ``ethical AI''; (2) we
               present empirical findings from our study on the
               operationalization of ``ethics'' in German AI start-ups to
               underline that AI ethics and social practices must be understood
               in their specific cultural and historical contexts; and (3)
               based on our empirical findings, suggest that ``ethical AI''
               practices can be broken down into principles, needs, narratives,
               materializations, and cultural genealogies to form a useful
               backdrop for considering socio-technical innovations. We
               conclude with critical reflections and practical implications of
               our work, as well as recommendations for future research.",
  publisher = "Association for Computing Machinery",
  pages     = "935--947",
  series    = "FAccT '22",
  month     =  jun,
  year      =  2022,
  address   = "New York, NY, USA",
  keywords  = "regulation, start-ups, fairness, social practice, transparency,
               innovation, AI ethics, organizations, socio-cultural history,
               accountability",
  location  = "Seoul, Republic of Korea"
}
